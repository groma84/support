<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,shrink-to-fit=no"><title>Computer Vision / List.community</title><script type="text/javascript">!function(i){if(i.search){var a={};i.search.slice(1).split("&").forEach(function(i){var l=i.split("=");a[l[0]]=l.slice(1).join("=").replace(/~and~/g,"&")}),void 0!==a.p&&window.history.replaceState(null,null,i.pathname.slice(0,-1)+(a.p||"")+(a.q?"?"+a.q:"")+i.hash)}}(window.location)</script><script src="https://cdn.ravenjs.com/3.21.0/raven.min.js" crossorigin="anonymous"></script><link href="https://fonts.googleapis.com/css?family=Karla:400,700,700i" rel="stylesheet"><link href="/static/css/main.b8c1ca79.css" rel="stylesheet"><link rel="icon" type="image/png" href="/favicon.png?size=32" data-react-helmet="true"><meta name="description" content="List.community is an easy way to browse curated lists on GitHub." data-react-helmet="true"><meta property="og:url" content="https://list.community" data-react-helmet="true"><meta property="og:site_name" content="List.community" data-react-helmet="true"><meta property="og:title" content="Computer Vision / List.community" data-react-helmet="true"><meta property="og:description" content="List.community is an easy way to browse curated lists on GitHub." data-react-helmet="true"><meta property="og:image" content="https://list.community/avatar.png" data-react-helmet="true"><meta name="twitter:card" content="summary" data-react-helmet="true"><meta name="twitter:title" content="Computer Vision / List.community" data-react-helmet="true"><meta name="twitter:description" content="List.community is an easy way to browse curated lists on GitHub." data-react-helmet="true"><meta name="twitter:image" content="https://list.community/avatar.png" data-react-helmet="true"><link rel="preload" as="script" href="/static/js/main.510da053.js"></head><body><div id="root"><div class="overflow-x-hidden bg-white min-h-screen pt-15 lg:pt-0"><div class="lg:mr-80"><div class="fixed pin-x pin-t z-20 lg:mr-80"><header class="select-none bg-black shadow-md text-black" style="background:#fff"><div class="max-w-xl mx-auto flex items-center h-15 pb-1 px-1 xl:px-5"><a class="link-reset p-3 mr-2" href="/"><h1 class="text-xl font-semibold font-sans tracking-wide">List.community</h1></a><div class="text-xl hidden xl:block truncate">jbhuang0604/awesome-computer-vision</div><div class="flex-1"></div><a href="https://github.com/jbhuang0604/awesome-computer-vision" class="link-reset p-3 pt-4 hidden sm:block flex-none">Submit a resource</a><a href="https://github.com/jbhuang0604/awesome-computer-vision/graphs/contributors" class="link-reset p-3 pt-4 hidden sm:block flex-none">Curators</a><a href="https://github.com/jbhuang0604/awesome-computer-vision" class="link-reset p-3 pt-4 leading-none flex-none"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16"><path d="m8 0c-4.42 0-8 3.582-8 8 0 3.535 2.292 6.533 5.47 7.59.4.075.547-.172.547-.385 0-.19-.007-.693-.01-1.36-2.225.483-2.695-1.073-2.695-1.073-.364-.923-.89-1.17-.89-1.17-.725-.496.056-.486.056-.486.803.056 1.225.824 1.225.824.713 1.223 1.873.87 2.33.665.072-.517.278-.87.507-1.07-1.777-.2-3.644-.888-3.644-3.953 0-.873.31-1.587.823-2.147-.09-.202-.36-1.015.07-2.117 0 0 .67-.215 2.2.82.64-.178 1.32-.266 2-.27.68.004 1.36.092 2 .27 1.52-1.035 2.19-.82 2.19-.82.43 1.102.16 1.915.08 2.117.51.56.82 1.273.82 2.147 0 3.073-1.87 3.75-3.65 3.947.28.24.54.731.54 1.48 0 1.071-.01 1.931-.01 2.191 0 .21.14.46.55.38 3.201-1.049 5.491-4.049 5.491-7.579 0-4.418-3.582-8-8-8"></path></svg></a><div class="cursor-pointer lg:hidden p-3 pt-4 leading-none flex-none"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" width="16" height="16"><path d="M0 3h20v2H0V3zm0 6h20v2H0V9zm0 6h20v2H0v-2z"></path></svg></div></div></header></div><div class="w-full lg:pt-15"><div id="table-of-contents"></div><div id="start-of-content"></div><div id="contents"></div><div id="readme" class="markdown-body p-4 xl:p-8 max-w-xl mx-auto"><h1><a href="#awesome-computer-vision-" aria-hidden="true" class="anchor" id="user-content-awesome-computer-vision-"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Awesome Computer Vision: <a target="_blank" rel="noopener noreferrer" href="https://github.com/sindresorhus/awesome"><img alt="Awesome" target="_blank" rel="noopener noreferrer" src="https://camo.githubusercontent.com/13c4e50d88df7178ae1882a203ed57b641674f94/68747470733a2f2f63646e2e7261776769742e636f6d2f73696e647265736f726875732f617765736f6d652f643733303566333864323966656437386661383536353265336136336531353464643865383832392f6d656469612f62616467652e737667" data-canonical-src="https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg" style="max-width:100%"></a></h1>
<p>A curated list of awesome computer vision resources, inspired by <a id="user-content-ziadoz/awesome-php" target="_blank" rel="noopener noreferrer" href="https://github.com/ziadoz/awesome-php">awesome-php</a><span class="ml-1 text-grey-dark whitespace-no-wrap"><span class="text-orange-dark">16k <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 14 13" width="14" height="12" class="mr-1"><polygon points="14 5 9.1 4.36 7 0 4.9 4.36 0 5 3.6 8.26 2.67 13 7 10.67 11.33 13 10.4 8.26"></polygon></svg></span><span class="text-green-dark">3k <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 14" width="10" height="12"><path d="M8,-8.47032947e-22 C7.09660216,-0.00238695453 6.3045861,0.603179379 6.07006224,1.47560813 C5.83553838,2.34803688 6.21717019,3.26909995 7,3.72 L7,5 L5,7 L3,5 L3,3.72 C3.78282981,3.26909995 4.16446162,2.34803688 3.92993776,1.47560813 C3.6954139,0.603179379 2.90339784,-0.00238695453 2,-4.44088363e-16 C1.09660216,-0.00238695453 0.304586097,0.603179379 0.0700622397,1.47560813 C-0.164461618,2.34803688 0.217170191,3.26909995 1,3.72 L1,5.5 L4,8.5 L4,10.28 C3.21717019,10.7309 2.83553838,11.6519631 3.07006224,12.5243919 C3.3045861,13.3968206 4.09660216,14.002387 5,14 C5.90339784,14.002387 6.6954139,13.3968206 6.92993776,12.5243919 C7.16446162,11.6519631 6.78282981,10.7309 6,10.28 L6,8.5 L9,5.5 L9,3.72 C9.78282981,3.26909995 10.1644616,2.34803688 9.92993776,1.47560813 C9.6954139,0.603179379 8.90339784,-0.00238695453 8,-8.47032947e-22 Z M2,3.2 C1.34,3.2 0.8,2.65 0.8,2 C0.8,1.35 1.35,0.8 2,0.8 C2.65,0.8 3.2,1.35 3.2,2 C3.2,2.65 2.65,3.2 2,3.2 Z M5,13.2 C4.34,13.2 3.8,12.65 3.8,12 C3.8,11.35 4.35,10.8 5,10.8 C5.65,10.8 6.2,11.35 6.2,12 C6.2,12.65 5.65,13.2 5,13.2 Z M8,3.2 C7.34,3.2 6.8,2.65 6.8,2 C6.8,1.35 7.35,0.8 8,0.8 C8.65,0.8 9.2,1.35 9.2,2 C9.2,2.65 8.65,3.2 8,3.2 Z"></path></svg></span></span>.</p>
<p>For a list people in computer vision listed with their academic genealogy, please visit <a target="_blank" rel="noopener noreferrer" href="https://github.com/jbhuang0604/awesome-computer-vision/blob/master/people.md">here</a></p>
<h2><a href="#contributing" aria-hidden="true" class="anchor" id="user-content-contributing"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Contributing</h2>
<p>Please feel free to send me <a target="_blank" rel="noopener noreferrer" href="https://github.com/jbhuang0604/awesome-computer-vision/pulls">pull requests</a> or email (<a target="_blank" rel="noopener noreferrer" href="mailto:jbhuang1@illinois.edu">jbhuang1@illinois.edu</a>) to add links.</p>
<h2 style="display:none"><a href="#table-of-contents" aria-hidden="true" class="anchor" id="user-content-table-of-contents"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Table of Contents</h2>
<ul style="display:none">
<li><a href="#books">Books</a></li>
<li><a href="#courses">Courses</a></li>
<li><a href="#papers">Papers</a></li>
<li><a href="#software">Software</a></li>
<li><a href="#datasets">Datasets</a></li>
<li><a href="#tutorials-and-talks">Tutorials and Talks</a></li>
<li><a href="#resources-for-students">Resources for students</a></li>
<li><a href="#blogs">Blogs</a></li>
<li><a href="#links">Links</a></li>
<li><a href="#songs">Songs</a></li>
</ul>
<h2><a href="#books" aria-hidden="true" class="anchor" id="user-content-books"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Books</h2>
<h4><a href="#computer-vision" aria-hidden="true" class="anchor" id="user-content-computer-vision"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Computer Vision</h4>
<ul>
<li><a target="_blank" rel="nofollow" href="http://www.computervisionmodels.com/">Computer Vision:  Models, Learning, and Inference</a> - Simon J. D. Prince 2012</li>
<li><a target="_blank" rel="nofollow" href="http://szeliski.org/Book/">Computer Vision: Theory and Application</a> - Rick Szeliski 2010</li>
<li><a target="_blank" rel="nofollow" href="http://www.amazon.com/Computer-Vision-Modern-Approach-2nd/dp/013608592X/ref=dp_ob_title_bk">Computer Vision: A Modern Approach (2nd edition)</a> - David Forsyth and Jean Ponce 2011</li>
<li><a target="_blank" rel="nofollow" href="http://www.robots.ox.ac.uk/%7Evgg/hzbook/">Multiple View Geometry in Computer Vision</a> - Richard Hartley and Andrew Zisserman 2004</li>
<li><a target="_blank" rel="nofollow" href="http://www.amazon.com/Computer-Vision-Linda-G-Shapiro/dp/0130307963">Computer Vision</a> - Linda G. Shapiro 2001</li>
<li><a target="_blank" rel="nofollow" href="http://www.amazon.com/Vision-Science-Phenomenology-Stephen-Palmer/dp/0262161834/">Vision Science: Photons to Phenomenology</a> - Stephen E. Palmer 1999</li>
<li><a target="_blank" rel="nofollow" href="http://www.morganclaypool.com/doi/abs/10.2200/S00332ED1V01Y201103AIM011">Visual Object Recognition synthesis lecture</a> - Kristen Grauman and Bastian Leibe 2011</li>
<li><a target="_blank" rel="nofollow" href="http://cvfxbook.com/">Computer Vision for Visual Effects</a> - Richard J. Radke, 2012</li>
<li><a target="_blank" rel="nofollow" href="http://www.amazon.com/High-Dynamic-Range-Imaging-Second/dp/012374914X">High dynamic range imaging: acquisition, display, and image-based lighting</a> - Reinhard, E., Heidrich, W., Debevec, P., Pattanaik, S., Ward, G., Myszkowski, K 2010</li>
<li><a target="_blank" rel="nofollow" href="https://people.csail.mit.edu/jsolomon/share/book/numerical_book.pdf">Numerical Algorithms: Methods for Computer Vision, Machine Learning, and Graphics</a> - Justin Solomon 2015</li>
</ul>
<h4><a href="#opencv-programming" aria-hidden="true" class="anchor" id="user-content-opencv-programming"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>OpenCV Programming</h4>
<ul>
<li><a target="_blank" rel="nofollow" href="http://www.amazon.com/Learning-OpenCV-Computer-Vision-Library/dp/0596516134">Learning OpenCV: Computer Vision with the OpenCV Library</a> - Gary Bradski and Adrian Kaehler</li>
<li><a target="_blank" rel="nofollow" href="https://www.pyimagesearch.com/practical-python-opencv/">Practical Python and OpenCV</a> - Adrian Rosebrock</li>
<li><a target="_blank" rel="nofollow" href="http://www.amazon.com/OpenCV-Essentials-Oscar-Deniz-Suarez/dp/1783984244/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1424594237&amp;sr=1-1&amp;keywords=opencv+essentials#">OpenCV Essentials</a> - Oscar Deniz Suarez, Mª del Milagro Fernandez Carrobles, Noelia Vallez Enano, Gloria Bueno Garcia, Ismael Serrano Gracia</li>
</ul>
<h4><a href="#machine-learning" aria-hidden="true" class="anchor" id="user-content-machine-learning"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Machine Learning</h4>
<ul>
<li><a target="_blank" rel="nofollow" href="http://research.microsoft.com/en-us/um/people/cmbishop/prml/index.htm">Pattern Recognition and Machine Learning</a> - Christopher M. Bishop 2007</li>
<li><a target="_blank" rel="nofollow" href="http://www.engineering.upm.ro/master-ie/sacpi/mat_did/info068/docum/Neural%20Networks%20for%20Pattern%20Recognition.pdf">Neural Networks for Pattern Recognition</a> - Christopher M. Bishop 1995</li>
<li><a target="_blank" rel="nofollow" href="http://pgm.stanford.edu/">Probabilistic Graphical Models: Principles and Techniques</a> - Daphne Koller and Nir Friedman 2009</li>
<li><a target="_blank" rel="nofollow" href="http://www.amazon.com/Pattern-Classification-2nd-Richard-Duda/dp/0471056693">Pattern Classification</a> - Peter E. Hart, David G. Stork, and Richard O. Duda 2000</li>
<li><a target="_blank" rel="nofollow" href="http://www.amazon.com/Machine-Learning-Tom-M-Mitchell/dp/0070428077/">Machine Learning</a> - Tom M. Mitchell 1997</li>
<li><a target="_blank" rel="nofollow" href="http://www.gaussianprocess.org/gpml/">Gaussian processes for machine learning</a> - Carl Edward Rasmussen and Christopher K. I. Williams 2005</li>
<li><a target="_blank" rel="nofollow" href="https://work.caltech.edu/telecourse.html">Learning From Data</a>- Yaser S. Abu-Mostafa, Malik Magdon-Ismail and Hsuan-Tien Lin 2012</li>
<li><a target="_blank" rel="nofollow" href="http://neuralnetworksanddeeplearning.com/">Neural Networks and Deep Learning</a> - Michael Nielsen 2014</li>
<li><a target="_blank" rel="nofollow" href="http://www.cs.ucl.ac.uk/staff/d.barber/brml/">Bayesian Reasoning and Machine Learning</a> - David Barber, Cambridge University Press, 2012</li>
</ul>
<h4><a href="#fundamentals" aria-hidden="true" class="anchor" id="user-content-fundamentals"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Fundamentals</h4>
<ul>
<li><a target="_blank" rel="nofollow" href="http://www.amazon.com/Linear-Algebra-Its-Applications-4th/dp/0030105676/ref=sr_1_4?ie=UTF8&amp;qid=1421433773&amp;sr=8-4&amp;keywords=Linear+Algebra+and+Its+Applications">Linear Algebra and Its Applications</a> - Gilbert Strang 1995</li>
</ul>
<h2><a href="#courses" aria-hidden="true" class="anchor" id="user-content-courses"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Courses</h2>
<h4><a href="#computer-vision-1" aria-hidden="true" class="anchor" id="user-content-computer-vision-1"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Computer Vision</h4>
<ul>
<li><a target="_blank" rel="nofollow" href="http://inside.mines.edu/%7Ewhoff/courses/EENG512/">EENG 512 / CSCI 512 - Computer Vision</a> - William Hoff (Colorado School of Mines)</li>
<li><a target="_blank" rel="nofollow" href="https://sites.google.com/site/ucbcs29443/">Visual Object and Activity Recognition</a> - Alexei A. Efros and Trevor Darrell (UC Berkeley)</li>
<li><a target="_blank" rel="nofollow" href="http://courses.cs.washington.edu/courses/cse455/12wi/">Computer Vision</a> - Steve Seitz (University of Washington)</li>
<li>Visual Recognition <a target="_blank" rel="nofollow" href="http://vision.cs.utexas.edu/381V-spring2016/">Spring 2016</a>, <a target="_blank" rel="nofollow" href="http://vision.cs.utexas.edu/381V-fall2016/">Fall 2016</a> - Kristen Grauman (UT Austin)</li>
<li><a target="_blank" rel="nofollow" href="http://www.tamaraberg.com/teaching/Spring_15/">Language and Vision</a> - Tamara Berg (UNC Chapel Hill)</li>
<li><a target="_blank" rel="nofollow" href="http://vision.stanford.edu/teaching/cs231n/">Convolutional Neural Networks for Visual Recognition</a> - Fei-Fei Li and Andrej Karpathy (Stanford University)</li>
<li><a target="_blank" rel="nofollow" href="http://cs.nyu.edu/%7Efergus/teaching/vision/index.html">Computer Vision</a> - Rob Fergus (NYU)</li>
<li><a target="_blank" rel="nofollow" href="https://courses.engr.illinois.edu/cs543/sp2015/">Computer Vision</a> - Derek Hoiem (UIUC)</li>
<li><a target="_blank" rel="nofollow" href="http://vision.stanford.edu/teaching/cs131_fall1415/index.html">Computer Vision: Foundations and Applications</a> - Kalanit Grill-Spector and Fei-Fei Li (Stanford University)</li>
<li><a target="_blank" rel="nofollow" href="http://vision.stanford.edu/teaching/cs431_spring1314/">High-Level Vision: Behaviors, Neurons and Computational Models</a> - Fei-Fei Li (Stanford University)</li>
<li><a target="_blank" rel="nofollow" href="http://6.869.csail.mit.edu/fa15/">Advances in Computer Vision</a> - Antonio Torralba and Bill Freeman (MIT)</li>
<li><a target="_blank" rel="nofollow" href="http://www.vision.rwth-aachen.de/course/11/">Computer Vision</a> - Bastian Leibe (RWTH Aachen University)</li>
<li><a target="_blank" rel="nofollow" href="http://www.vision.rwth-aachen.de/course/9/">Computer Vision 2</a> - Bastian Leibe (RWTH Aachen University)</li>
<li><a target="_blank" rel="nofollow" href="http://klewel.com/conferences/epfl-computer-vision/">Computer Vision</a> Pascal Fua (EPFL):</li>
<li><a target="_blank" rel="nofollow" href="http://cvlab-dresden.de/courses/computer-vision-1/">Computer Vision 1</a> Carsten Rother (TU Dresden):</li>
<li><a target="_blank" rel="nofollow" href="http://cvlab-dresden.de/courses/CV2/">Computer Vision 2</a> Carsten Rother (TU Dresden):</li>
<li><a target="_blank" rel="nofollow" href="https://youtu.be/RDkwklFGMfo?list=PLTBdjV_4f-EJn6udZ34tht9EVIW7lbeo4">Multiple View Geometry</a> Daniel Cremers (TU Munich):</li>
</ul>
<h4><a href="#computational-photography" aria-hidden="true" class="anchor" id="user-content-computational-photography"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Computational Photography</h4>
<ul>
<li><a target="_blank" rel="nofollow" href="http://inst.eecs.berkeley.edu/%7Ecs194-26/fa14/">Image Manipulation and Computational Photography</a> - Alexei A. Efros (UC Berkeley)</li>
<li><a target="_blank" rel="nofollow" href="http://graphics.cs.cmu.edu/courses/15-463/2012_fall/463.html">Computational Photography</a> - Alexei A. Efros (CMU)</li>
<li><a target="_blank" rel="nofollow" href="https://courses.engr.illinois.edu/cs498dh3/">Computational Photography</a> - Derek Hoiem (UIUC)</li>
<li><a target="_blank" rel="nofollow" href="http://cs.brown.edu/courses/csci1290/">Computational Photography</a> - James Hays (Brown University)</li>
<li><a target="_blank" rel="nofollow" href="http://stellar.mit.edu/S/course/6/sp12/6.815/">Digital &amp; Computational Photography</a> - Fredo Durand (MIT)</li>
<li><a target="_blank" rel="nofollow" href="http://ocw.mit.edu/courses/media-arts-and-sciences/mas-531-computational-camera-and-photography-fall-2009/">Computational Camera and Photography</a> - Ramesh Raskar (MIT Media Lab)</li>
<li><a target="_blank" rel="nofollow" href="https://www.udacity.com/course/computational-photography--ud955">Computational Photography</a> - Irfan Essa (Georgia Tech)</li>
<li><a target="_blank" rel="nofollow" href="http://graphics.stanford.edu/courses/">Courses in Graphics</a> - Stanford University</li>
<li><a target="_blank" rel="nofollow" href="http://cs.nyu.edu/%7Efergus/teaching/comp_photo/index.html">Computational Photography</a> - Rob Fergus (NYU)</li>
<li><a target="_blank" rel="nofollow" href="http://www.cs.toronto.edu/%7Ekyros/courses/320/">Introduction to Visual Computing</a> - Kyros Kutulakos (University of Toronto)</li>
<li><a target="_blank" rel="nofollow" href="http://www.cs.toronto.edu/%7Ekyros/courses/2530/">Computational Photography</a> - Kyros Kutulakos (University of Toronto)</li>
<li><a target="_blank" rel="nofollow" href="https://www.ecse.rpi.edu/%7Erjradke/cvfxcourse.html">Computer Vision for Visual Effects</a> - Rich Radke (Rensselaer Polytechnic Institute)</li>
<li><a target="_blank" rel="nofollow" href="https://www.ecse.rpi.edu/%7Erjradke/improccourse.html">Introduction to Image Processing</a> - Rich Radke (Rensselaer Polytechnic Institute)</li>
</ul>
<h4><a href="#machine-learning-and-statistical-learning" aria-hidden="true" class="anchor" id="user-content-machine-learning-and-statistical-learning"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Machine Learning and Statistical Learning</h4>
<ul>
<li><a target="_blank" rel="nofollow" href="https://www.coursera.org/learn/machine-learning">Machine Learning</a> - Andrew Ng (Stanford University)</li>
<li><a target="_blank" rel="nofollow" href="https://work.caltech.edu/telecourse.html">Learning from Data</a> - Yaser S. Abu-Mostafa (Caltech)</li>
<li><a target="_blank" rel="nofollow" href="https://class.stanford.edu/courses/HumanitiesandScience/StatLearning/Winter2015/about">Statistical Learning</a> - Trevor Hastie and Rob Tibshirani (Stanford University)</li>
<li><a target="_blank" rel="nofollow" href="http://www.mit.edu/%7E9.520/fall14/">Statistical Learning Theory and Applications</a> - Tomaso Poggio, Lorenzo Rosasco, Carlo Ciliberto, Charlie Frogner, Georgios Evangelopoulos, Ben Deen (MIT)</li>
<li><a target="_blank" rel="nofollow" href="http://www.stat.rice.edu/%7Egallen/stat640.html">Statistical Learning</a> - Genevera Allen (Rice University)</li>
<li><a target="_blank" rel="nofollow" href="http://www.cs.berkeley.edu/%7Ejordan/courses/294-fall09/">Practical Machine Learning</a> - Michael Jordan (UC Berkeley)</li>
<li><a target="_blank" rel="nofollow" href="http://videolectures.net/course_information_theory_pattern_recognition/">Course on Information Theory, Pattern Recognition, and Neural Networks</a> - David MacKay (University of Cambridge)</li>
<li><a target="_blank" rel="nofollow" href="http://web.stanford.edu/%7Elmackey/stats306b/">Methods for Applied Statistics: Unsupervised Learning</a> - Lester Mackey (Stanford)</li>
<li><a target="_blank" rel="nofollow" href="http://www.robots.ox.ac.uk/%7Eaz/lectures/ml/index.html">Machine Learning</a> - Andrew Zisserman (University of Oxford)</li>
<li><a target="_blank" rel="nofollow" href="https://www.udacity.com/course/intro-to-machine-learning--ud120">Intro to Machine Learning</a> - Sebastian Thrun (Stanford University)</li>
<li><a target="_blank" rel="nofollow" href="https://www.udacity.com/course/machine-learning--ud262">Machine Learning</a> - Charles Isbell, Michael Littman (Georgia Tech)</li>
<li><a target="_blank" rel="nofollow" href="https://cs231n.github.io/">(Convolutional) Neural Networks for Visual Recognition</a> - Fei-Fei Li, Andrej Karphaty, Justin Johnson (Stanford University)</li>
<li><a target="_blank" rel="nofollow" href="https://youtu.be/QZmZFeZxEKI?list=PLTBdjV_4f-EIiongKlS9OKrBEp8QR47Wl">Machine Learning for Computer Vision</a> - Rudolph Triebel (TU Munich)</li>
</ul>
<h4><a href="#optimization" aria-hidden="true" class="anchor" id="user-content-optimization"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Optimization</h4>
<ul>
<li><a target="_blank" rel="nofollow" href="http://stanford.edu/class/ee364a/">Convex Optimization I</a> - Stephen Boyd (Stanford University)</li>
<li><a target="_blank" rel="nofollow" href="http://stanford.edu/class/ee364b/">Convex Optimization II</a> - Stephen Boyd (Stanford University)</li>
<li><a target="_blank" rel="nofollow" href="https://class.stanford.edu/courses/Engineering/CVX101/Winter2014/about">Convex Optimization</a> - Stephen Boyd (Stanford University)</li>
<li><a target="_blank" rel="nofollow" href="http://optimization.mit.edu/classes.php">Optimization at MIT</a> - (MIT)</li>
<li><a target="_blank" rel="nofollow" href="http://www.stat.cmu.edu/%7Eryantibs/convexopt/">Convex Optimization</a> - Ryan Tibshirani (CMU)</li>
</ul>
<h2><a href="#papers" aria-hidden="true" class="anchor" id="user-content-papers"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Papers</h2>
<h4><a href="#conference-papers-on-the-web" aria-hidden="true" class="anchor" id="user-content-conference-papers-on-the-web"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Conference papers on the web</h4>
<ul>
<li><a target="_blank" rel="nofollow" href="http://www.cvpapers.com/">CVPapers</a> - Computer vision papers on the web</li>
<li><a target="_blank" rel="nofollow" href="http://kesen.realtimerendering.com/">SIGGRAPH Paper on the web</a> - Graphics papers on the web</li>
<li><a target="_blank" rel="nofollow" href="http://papers.nips.cc/">NIPS Proceedings</a> - NIPS papers on the web</li>
<li><a target="_blank" rel="nofollow" href="http://www.cv-foundation.org/openaccess/menu.py">Computer Vision Foundation open access</a></li>
<li><a target="_blank" rel="nofollow" href="http://iris.usc.edu/Vision-Notes/bibliography/contents.html">Annotated Computer Vision Bibliography</a> - Keith Price (USC)</li>
<li><a target="_blank" rel="nofollow" href="http://iris.usc.edu/Information/Iris-Conferences.html">Calendar of Computer Image Analysis, Computer Vision Conferences</a> - (USC)</li>
</ul>
<h4><a href="#survey-papers" aria-hidden="true" class="anchor" id="user-content-survey-papers"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Survey Papers</h4>
<ul>
<li><a target="_blank" rel="nofollow" href="http://surveys.visionbib.com/index.html">Visionbib Survey Paper List</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.nowpublishers.com/CGV">Foundations and Trends® in Computer Graphics and Vision</a></li>
<li><a target="_blank" rel="nofollow" href="http://link.springer.com/book/10.1007/978-0-387-31439-6">Computer Vision: A Reference Guide</a></li>
</ul>
<h2><a href="#tutorials-and-talks" aria-hidden="true" class="anchor" id="user-content-tutorials-and-talks"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Tutorials and talks</h2>
<h4><a href="#computer-vision-2" aria-hidden="true" class="anchor" id="user-content-computer-vision-2"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Computer Vision</h4>
<ul>
<li><a target="_blank" rel="nofollow" href="http://www.computervisiontalks.com/">Computer Vision Talks</a> - Lectures, keynotes, panel discussions on computer vision</li>
<li><a target="_blank" rel="nofollow" href="https://www.youtube.com/watch?v=Mqg6eorYRIQ">The Three R's of Computer Vision</a> - Jitendra Malik (UC Berkeley) 2013</li>
<li><a target="_blank" rel="nofollow" href="http://videolectures.net/epsrcws08_blake_amv/">Applications to Machine Vision</a> - Andrew Blake (Microsoft Research) 2008</li>
<li><a target="_blank" rel="nofollow" href="http://videolectures.net/kdd08_malik_fis/?q=image">The Future of Image Search</a> - Jitendra Malik (UC Berkeley) 2008</li>
<li><a target="_blank" rel="nofollow" href="https://www.youtube.com/watch?v=M17oGxh3Ny8">Should I do a PhD in Computer Vision?</a> - Fatih Porikli (Australian National University)</li>
</ul>
<ul>
<li><a target="_blank" rel="nofollow" href="http://www.ipam.ucla.edu/programs/summer-schools/graduate-summer-school-computer-vision/?tab=schedule">Graduate Summer School 2013: Computer Vision</a> - IPAM, 2013</li>
</ul>
<h4><a href="#recent-conference-talks" aria-hidden="true" class="anchor" id="user-content-recent-conference-talks"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Recent Conference Talks</h4>
<ul>
<li><a target="_blank" rel="nofollow" href="http://www.pamitc.org/cvpr15/">CVPR 2015</a> - Jun 2015</li>
<li><a target="_blank" rel="nofollow" href="http://videolectures.net/eccv2014_zurich/">ECCV 2014</a> - Sep 2014</li>
<li><a target="_blank" rel="nofollow" href="http://techtalks.tv/cvpr-2014-oral-talks/">CVPR 2014</a> - Jun 2014</li>
<li><a target="_blank" rel="nofollow" href="http://techtalks.tv/iccv2013/">ICCV 2013</a> - Dec 2013</li>
<li><a target="_blank" rel="nofollow" href="http://techtalks.tv/icml/2013/">ICML 2013</a> - Jul 2013</li>
<li><a target="_blank" rel="nofollow" href="http://techtalks.tv/cvpr2013/">CVPR 2013</a> - Jun 2013</li>
<li><a target="_blank" rel="nofollow" href="http://videolectures.net/eccv2012_firenze/">ECCV 2012</a> - Oct 2012</li>
<li><a target="_blank" rel="nofollow" href="http://techtalks.tv/icml/2012/orals/">ICML 2012</a> - Jun 2012</li>
<li><a target="_blank" rel="nofollow" href="http://techtalks.tv/cvpr2012webcast/">CVPR 2012</a> - Jun 2012</li>
</ul>
<h4><a href="#3d-computer-vision" aria-hidden="true" class="anchor" id="user-content-3d-computer-vision"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>3D Computer Vision</h4>
<ul>
<li><a target="_blank" rel="nofollow" href="https://www.youtube.com/watch?v=kyIzMr917Rc">3D Computer Vision: Past, Present, and Future</a> - Steve Seitz (University of Washington) 2011</li>
<li><a target="_blank" rel="nofollow" href="https://www.youtube.com/watch?v=04Kgg3QEXFI">Reconstructing the World from Photos on the Internet</a> - Steve Seitz (University of Washington) 2013</li>
</ul>
<h4><a href="#internet-vision" aria-hidden="true" class="anchor" id="user-content-internet-vision"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Internet Vision</h4>
<ul>
<li><a target="_blank" rel="nofollow" href="http://www.technologyreview.com/video/426265/meet-2011-tr35-winner-noah-snavely/">The Distributed Camera</a> - Noah Snavely (Cornell University) 2011</li>
<li><a target="_blank" rel="nofollow" href="https://www.youtube.com/watch?v=UHkCa9-Z1Ps">Planet-Scale Visual Understanding</a> - Noah Snavely (Cornell University) 2014</li>
<li><a target="_blank" rel="nofollow" href="https://www.youtube.com/watch?v=6MWEfpKUfRc">A Trillion Photos</a> - Steve Seitz (University of Washington) 2013</li>
</ul>
<h4><a href="#computational-photography-1" aria-hidden="true" class="anchor" id="user-content-computational-photography-1"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Computational Photography</h4>
<ul>
<li><a target="_blank" rel="nofollow" href="https://www.youtube.com/watch?v=j90_0Ndk7XM">Reflections on Image-Based Modeling and Rendering</a> - Richard Szeliski (Microsoft Research) 2013</li>
<li><a target="_blank" rel="nofollow" href="https://www.youtube.com/watch?v=ZvPaHZZVPRk">Photographing Events over Time</a> - William T. Freeman (MIT) 2011</li>
<li><a target="_blank" rel="nofollow" href="http://videolectures.net/nipsworkshops2011_weiss_deconvolution/">Old and New algorithm for Blind Deconvolution</a> -  Yair Weiss (The Hebrew University of Jerusalem) 2011</li>
<li><a target="_blank" rel="nofollow" href="http://videolectures.net/nipsworkshops2010_milanfar_tmi/">A Tour of Modern "Image Processing"</a> -  Peyman Milanfar (UC Santa Cruz/Google) 2010</li>
<li><a target="_blank" rel="nofollow" href="http://videolectures.net/mlss07_blake_tiivp/">Topics in image and video processing</a> Andrew Blake (Microsoft Research) 2007</li>
<li><a target="_blank" rel="nofollow" href="https://www.youtube.com/watch?v=HJVNI0mkmqk">Computational Photography</a> - William T. Freeman (MIT) 2012</li>
<li><a target="_blank" rel="nofollow" href="https://www.youtube.com/watch?v=_BWnIQY_X98">Revealing the Invisible</a> - Frédo Durand (MIT) 2012</li>
<li><a target="_blank" rel="nofollow" href="https://www.youtube.com/watch?v=rE-hVtytT-I">Overview of Computer Vision and Visual Effects</a> - Rich Radke (Rensselaer Polytechnic Institute) 2014</li>
</ul>
<h4><a href="#learning-and-vision" aria-hidden="true" class="anchor" id="user-content-learning-and-vision"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Learning and Vision</h4>
<ul>
<li><a target="_blank" rel="nofollow" href="http://videolectures.net/colt2011_freeman_help/?q=computer%20vision">Where machine vision needs help from machine learning</a> - William T. Freeman (MIT) 2011</li>
<li><a target="_blank" rel="nofollow" href="http://videolectures.net/mlss08au_lucey_linv/">Learning in Computer Vision</a> - Simon Lucey (CMU) 2008</li>
<li><a target="_blank" rel="nofollow" href="http://videolectures.net/nips09_weiss_lil/?q=computer%20vision">Learning and Inference in Low-Level Vision</a> - Yair Weiss (The Hebrew University of Jerusalem) 2009</li>
</ul>
<h4><a href="#object-recognition" aria-hidden="true" class="anchor" id="user-content-object-recognition"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Object Recognition</h4>
<ul>
<li><a target="_blank" rel="nofollow" href="http://research.microsoft.com/apps/video/dl.aspx?id=231358">Object Recognition</a> - Larry Zitnick (Microsoft Research)</li>
<li><a target="_blank" rel="nofollow" href="http://videolectures.net/mlas06_li_gmvoo/?q=Fei-Fei%20Li">Generative Models for Visual Objects and Object Recognition via Bayesian Inference</a> - Fei-Fei Li (Stanford University)</li>
</ul>
<h4><a href="#graphical-models" aria-hidden="true" class="anchor" id="user-content-graphical-models"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Graphical Models</h4>
<ul>
<li><a target="_blank" rel="nofollow" href="http://videolectures.net/uai2012_felzenszwalb_computer_vision/?q=computer%20vision">Graphical Models for Computer Vision</a> - Pedro Felzenszwalb (Brown University) 2012</li>
<li><a target="_blank" rel="nofollow" href="http://videolectures.net/mlss09uk_ghahramani_gm/">Graphical Models</a> - Zoubin Ghahramani (University of Cambridge) 2009</li>
<li><a target="_blank" rel="nofollow" href="http://videolectures.net/mlss06tw_roweis_mlpgm/">Machine Learning, Probability and Graphical Models</a> - Sam Roweis (NYU) 2006</li>
<li><a target="_blank" rel="nofollow" href="http://videolectures.net/mlss09us_weiss_gma/?q=Graphical%20Models">Graphical Models and Applications</a> -  Yair Weiss (The Hebrew University of Jerusalem) 2009</li>
</ul>
<h4><a href="#machine-learning-1" aria-hidden="true" class="anchor" id="user-content-machine-learning-1"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Machine Learning</h4>
<ul>
<li><a target="_blank" rel="nofollow" href="https://nikola-rt.ee.washington.edu/people/bulyko/papers/em.pdf">A Gentle Tutorial of the EM Algorithm</a> - Jeff A. Bilmes (UC Berkeley) 1998</li>
<li><a target="_blank" rel="nofollow" href="http://videolectures.net/mlss09uk_bishop_ibi/">Introduction To Bayesian Inference</a> - Christopher Bishop (Microsoft Research) 2009</li>
<li><a target="_blank" rel="nofollow" href="http://videolectures.net/mlss06tw_lin_svm/">Support Vector Machines</a> - Chih-Jen Lin (National Taiwan University) 2006</li>
<li><a target="_blank" rel="nofollow" href="http://videolectures.net/mlss09uk_jordan_bfway/">Bayesian or Frequentist, Which Are You? </a> - Michael I. Jordan (UC Berkeley)</li>
</ul>
<h4><a href="#optimization-1" aria-hidden="true" class="anchor" id="user-content-optimization-1"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Optimization</h4>
<ul>
<li><a target="_blank" rel="nofollow" href="http://videolectures.net/nips2010_wright_oaml/">Optimization Algorithms in Machine Learning</a> - Stephen J. Wright (University of Wisconsin-Madison)</li>
<li><a target="_blank" rel="nofollow" href="http://videolectures.net/mlss07_vandenberghe_copt/?q=convex%20optimization">Convex Optimization</a> - Lieven Vandenberghe (University of California, Los Angeles)</li>
<li><a target="_blank" rel="nofollow" href="https://www.youtube.com/watch?v=oZqoWozVDVg">Continuous Optimization in Computer Vision</a> - Andrew Fitzgibbon (Microsoft Research)</li>
<li><a target="_blank" rel="nofollow" href="http://videolectures.net/sahd2014_bach_stochastic_gradient/">Beyond stochastic gradient descent for large-scale machine learning</a> - Francis Bach (INRIA)</li>
<li><a target="_blank" rel="nofollow" href="https://www.youtube.com/playlist?list=PLTBdjV_4f-EJ7A2iIH5L5ztqqrWYjP2RI">Variational Methods for Computer Vision</a> - Daniel Cremers (Technische Universität München) (<a target="_blank" rel="nofollow" href="https://www.youtube.com/watch?v=GgcbVPNd3SI">lecture 18 missing from playlist</a>)</li>
</ul>
<h4><a href="#deep-learning" aria-hidden="true" class="anchor" id="user-content-deep-learning"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Deep Learning</h4>
<ul>
<li><a target="_blank" rel="nofollow" href="http://videolectures.net/jul09_hinton_deeplearn/">A tutorial on Deep Learning</a> - Geoffrey E. Hinton (University of Toronto)</li>
<li><a target="_blank" rel="nofollow" href="http://videolectures.net/kdd2014_salakhutdinov_deep_learning/?q=Hidden%20Markov%20model#">Deep Learning</a> -  Ruslan Salakhutdinov (University of Toronto)</li>
<li><a target="_blank" rel="nofollow" href="http://videolectures.net/kdd2014_bengio_deep_learning/">Scaling up Deep Learning</a> - Yoshua Bengio (University of Montreal)</li>
<li><a target="_blank" rel="nofollow" href="http://videolectures.net/machine_krizhevsky_imagenet_classification/?q=deep%20learning">ImageNet Classification with Deep Convolutional Neural Networks</a> -  Alex Krizhevsky (University of Toronto)</li>
<li><a target="_blank" rel="nofollow" href="http://videolectures.net/sahd2014_lecun_deep_learning/">The Unreasonable Effectivness Of Deep Learning</a> Yann LeCun (NYU/Facebook Research) 2014</li>
<li><a target="_blank" rel="nofollow" href="https://www.youtube.com/watch?v=qgx57X0fBdA">Deep Learning for Computer Vision</a> - Rob Fergus (NYU/Facebook Research)</li>
<li><a target="_blank" rel="nofollow" href="http://videolectures.net/sahd2014_mallat_dimensional_learning/">High-dimensional learning with deep network contractions</a> - Stéphane Mallat (Ecole Normale Superieure)</li>
<li><a target="_blank" rel="nofollow" href="http://www.ipam.ucla.edu/programs/summer-schools/graduate-summer-school-deep-learning-feature-learning/?tab=schedule">Graduate Summer School 2012: Deep Learning, Feature Learning</a> - IPAM, 2012</li>
<li><a target="_blank" rel="nofollow" href="http://www.fields.utoronto.ca/programs/scientific/14-15/bigdata/machine/">Workshop on Big Data and Statistical Machine Learning</a></li>
<li><a target="_blank" rel="nofollow" href="https://www.youtube.com/channel/UC3ywjSv5OsDiDAnOP8C1NiQ">Machine Learning Summer School</a> - Reykjavik, Iceland 2014
<ul>
<li><a target="_blank" rel="nofollow" href="https://www.youtube.com/watch?v=JuimBuvEWBg">Deep Learning Session 1</a> - Yoshua Bengio (Universtiy of Montreal)</li>
<li><a target="_blank" rel="nofollow" href="https://www.youtube.com/watch?v=Fl-W7_z3w3o">Deep Learning Session 2</a> - Yoshua Bengio (University of Montreal)</li>
<li><a target="_blank" rel="nofollow" href="https://www.youtube.com/watch?v=_cohR7LAgWA">Deep Learning Session 3</a> - Yoshua Bengio (University of Montreal)</li>
</ul>
</li>
</ul>
<h2><a href="#software" aria-hidden="true" class="anchor" id="user-content-software"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Software</h2>
<h4><a href="#external-resource-links" aria-hidden="true" class="anchor" id="user-content-external-resource-links"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>External Resource Links</h4>
<ul>
<li><a target="_blank" rel="nofollow" href="https://sites.google.com/site/jbhuang0604/resources/vision">Computer Vision Resources</a> - Jia-Bin Huang (UIUC)</li>
<li><a target="_blank" rel="nofollow" href="http://www.cvpapers.com/rr.html">Computer Vision Algorithm Implementations</a> - CVPapers</li>
<li><a target="_blank" rel="nofollow" href="http://www.csee.wvu.edu/%7Exinl/reproducible_research.html">Source Code Collection for Reproducible Research</a> - Xin Li (West Virginia University)</li>
<li><a target="_blank" rel="nofollow" href="http://www.cs.cmu.edu/afs/cs/project/cil/ftp/html/v-source.html">CMU Computer Vision Page</a></li>
</ul>
<h4><a href="#general-purpose-computer-vision-library" aria-hidden="true" class="anchor" id="user-content-general-purpose-computer-vision-library"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>General Purpose Computer Vision Library</h4>
<ul>
<li><a target="_blank" rel="nofollow" href="http://opencv.org/">Open CV</a></li>
<li><a target="_blank" rel="nofollow" href="http://kyamagu.github.io/mexopencv/">mexopencv</a></li>
<li><a target="_blank" rel="nofollow" href="http://simplecv.org/">SimpleCV</a></li>
<li><a id="user-content-jesolem/PCV" target="_blank" rel="noopener noreferrer" href="https://github.com/jesolem/PCV">Open source Python module for computer vision</a><span class="ml-1 text-grey-dark whitespace-no-wrap"><span class="text-orange-dark">531 <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 14 13" width="14" height="12" class="mr-1"><polygon points="14 5 9.1 4.36 7 0 4.9 4.36 0 5 3.6 8.26 2.67 13 7 10.67 11.33 13 10.4 8.26"></polygon></svg></span><span class="text-green-dark">140 <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 14" width="10" height="12"><path d="M8,-8.47032947e-22 C7.09660216,-0.00238695453 6.3045861,0.603179379 6.07006224,1.47560813 C5.83553838,2.34803688 6.21717019,3.26909995 7,3.72 L7,5 L5,7 L3,5 L3,3.72 C3.78282981,3.26909995 4.16446162,2.34803688 3.92993776,1.47560813 C3.6954139,0.603179379 2.90339784,-0.00238695453 2,-4.44088363e-16 C1.09660216,-0.00238695453 0.304586097,0.603179379 0.0700622397,1.47560813 C-0.164461618,2.34803688 0.217170191,3.26909995 1,3.72 L1,5.5 L4,8.5 L4,10.28 C3.21717019,10.7309 2.83553838,11.6519631 3.07006224,12.5243919 C3.3045861,13.3968206 4.09660216,14.002387 5,14 C5.90339784,14.002387 6.6954139,13.3968206 6.92993776,12.5243919 C7.16446162,11.6519631 6.78282981,10.7309 6,10.28 L6,8.5 L9,5.5 L9,3.72 C9.78282981,3.26909995 10.1644616,2.34803688 9.92993776,1.47560813 C9.6954139,0.603179379 8.90339784,-0.00238695453 8,-8.47032947e-22 Z M2,3.2 C1.34,3.2 0.8,2.65 0.8,2 C0.8,1.35 1.35,0.8 2,0.8 C2.65,0.8 3.2,1.35 3.2,2 C3.2,2.65 2.65,3.2 2,3.2 Z M5,13.2 C4.34,13.2 3.8,12.65 3.8,12 C3.8,11.35 4.35,10.8 5,10.8 C5.65,10.8 6.2,11.35 6.2,12 C6.2,12.65 5.65,13.2 5,13.2 Z M8,3.2 C7.34,3.2 6.8,2.65 6.8,2 C6.8,1.35 7.35,0.8 8,0.8 C8.65,0.8 9.2,1.35 9.2,2 C9.2,2.65 8.65,3.2 8,3.2 Z"></path></svg></span></span></li>
<li><a id="user-content-liuliu/ccv" target="_blank" rel="noopener noreferrer" href="https://github.com/liuliu/ccv">ccv: A Modern Computer Vision Library</a><span class="ml-1 text-grey-dark whitespace-no-wrap"><span class="text-orange-dark">6k <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 14 13" width="14" height="12" class="mr-1"><polygon points="14 5 9.1 4.36 7 0 4.9 4.36 0 5 3.6 8.26 2.67 13 7 10.67 11.33 13 10.4 8.26"></polygon></svg></span><span class="text-green-dark">1k <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 14" width="10" height="12"><path d="M8,-8.47032947e-22 C7.09660216,-0.00238695453 6.3045861,0.603179379 6.07006224,1.47560813 C5.83553838,2.34803688 6.21717019,3.26909995 7,3.72 L7,5 L5,7 L3,5 L3,3.72 C3.78282981,3.26909995 4.16446162,2.34803688 3.92993776,1.47560813 C3.6954139,0.603179379 2.90339784,-0.00238695453 2,-4.44088363e-16 C1.09660216,-0.00238695453 0.304586097,0.603179379 0.0700622397,1.47560813 C-0.164461618,2.34803688 0.217170191,3.26909995 1,3.72 L1,5.5 L4,8.5 L4,10.28 C3.21717019,10.7309 2.83553838,11.6519631 3.07006224,12.5243919 C3.3045861,13.3968206 4.09660216,14.002387 5,14 C5.90339784,14.002387 6.6954139,13.3968206 6.92993776,12.5243919 C7.16446162,11.6519631 6.78282981,10.7309 6,10.28 L6,8.5 L9,5.5 L9,3.72 C9.78282981,3.26909995 10.1644616,2.34803688 9.92993776,1.47560813 C9.6954139,0.603179379 8.90339784,-0.00238695453 8,-8.47032947e-22 Z M2,3.2 C1.34,3.2 0.8,2.65 0.8,2 C0.8,1.35 1.35,0.8 2,0.8 C2.65,0.8 3.2,1.35 3.2,2 C3.2,2.65 2.65,3.2 2,3.2 Z M5,13.2 C4.34,13.2 3.8,12.65 3.8,12 C3.8,11.35 4.35,10.8 5,10.8 C5.65,10.8 6.2,11.35 6.2,12 C6.2,12.65 5.65,13.2 5,13.2 Z M8,3.2 C7.34,3.2 6.8,2.65 6.8,2 C6.8,1.35 7.35,0.8 8,0.8 C8.65,0.8 9.2,1.35 9.2,2 C9.2,2.65 8.65,3.2 8,3.2 Z"></path></svg></span></span></li>
<li><a target="_blank" rel="nofollow" href="http://www.vlfeat.org/">VLFeat</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.mathworks.com/products/computer-vision/">Matlab Computer Vision System Toolbox</a></li>
<li><a target="_blank" rel="nofollow" href="http://vision.ucsd.edu/%7Epdollar/toolbox/doc/index.html">Piotr's Computer Vision Matlab Toolbox</a></li>
<li><a target="_blank" rel="nofollow" href="http://pointclouds.org/">PCL: Point Cloud Library</a></li>
<li><a target="_blank" rel="nofollow" href="https://gitorious.org/imageutilities">ImageUtilities</a></li>
</ul>
<h4><a href="#multiple-view-computer-vision" aria-hidden="true" class="anchor" id="user-content-multiple-view-computer-vision"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Multiple-view Computer Vision</h4>
<ul>
<li><a target="_blank" rel="nofollow" href="http://www.robots.ox.ac.uk/%7Evgg/hzbook/code/">MATLAB Functions for Multiple View Geometry</a></li>
<li><a target="_blank" rel="nofollow" href="http://staffhome.ecm.uwa.edu.au/%7E00011811/Research/MatlabFns/index.html">Peter Kovesi's Matlab Functions for Computer Vision and Image Analysis</a></li>
<li><a target="_blank" rel="nofollow" href="http://laurentkneip.github.io/opengv/">OpenGV </a> - geometric computer vision algorithms</li>
<li><a target="_blank" rel="nofollow" href="http://cmp.felk.cvut.cz/mini/">MinimalSolvers</a> - Minimal problems solver</li>
<li><a target="_blank" rel="nofollow" href="http://www.gcc.tu-darmstadt.de/home/proj/mve/">Multi-View Environment</a></li>
<li><a target="_blank" rel="nofollow" href="http://ccwu.me/vsfm/">Visual SFM</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.cs.cornell.edu/%7Esnavely/bundler/">Bundler SFM</a></li>
<li><a target="_blank" rel="nofollow" href="http://imagine.enpc.fr/%7Emoulonp/openMVG/">openMVG: open Multiple View Geometry</a> - Multiple View Geometry; Structure from Motion library &amp; softwares</li>
<li><a target="_blank" rel="nofollow" href="http://www.di.ens.fr/pmvs/">Patch-based Multi-view Stereo V2</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.di.ens.fr/cmvs/">Clustering Views for Multi-view Stereo</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.gris.informatik.tu-darmstadt.de/projects/floating-scale-surface-recon/">Floating Scale Surface Reconstruction</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.gcc.tu-darmstadt.de/home/proj/texrecon/">Large-Scale Texturing of 3D Reconstructions</a></li>
<li><a id="user-content-openMVG/awesome_3DReconstruction_list" target="_blank" rel="noopener noreferrer" href="https://github.com/openMVG/awesome_3DReconstruction_list">Awesome 3D reconstruction list</a><span class="ml-1 text-grey-dark whitespace-no-wrap"><span class="text-orange-dark">288 <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 14 13" width="14" height="12" class="mr-1"><polygon points="14 5 9.1 4.36 7 0 4.9 4.36 0 5 3.6 8.26 2.67 13 7 10.67 11.33 13 10.4 8.26"></polygon></svg></span><span class="text-green-dark">108 <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 14" width="10" height="12"><path d="M8,-8.47032947e-22 C7.09660216,-0.00238695453 6.3045861,0.603179379 6.07006224,1.47560813 C5.83553838,2.34803688 6.21717019,3.26909995 7,3.72 L7,5 L5,7 L3,5 L3,3.72 C3.78282981,3.26909995 4.16446162,2.34803688 3.92993776,1.47560813 C3.6954139,0.603179379 2.90339784,-0.00238695453 2,-4.44088363e-16 C1.09660216,-0.00238695453 0.304586097,0.603179379 0.0700622397,1.47560813 C-0.164461618,2.34803688 0.217170191,3.26909995 1,3.72 L1,5.5 L4,8.5 L4,10.28 C3.21717019,10.7309 2.83553838,11.6519631 3.07006224,12.5243919 C3.3045861,13.3968206 4.09660216,14.002387 5,14 C5.90339784,14.002387 6.6954139,13.3968206 6.92993776,12.5243919 C7.16446162,11.6519631 6.78282981,10.7309 6,10.28 L6,8.5 L9,5.5 L9,3.72 C9.78282981,3.26909995 10.1644616,2.34803688 9.92993776,1.47560813 C9.6954139,0.603179379 8.90339784,-0.00238695453 8,-8.47032947e-22 Z M2,3.2 C1.34,3.2 0.8,2.65 0.8,2 C0.8,1.35 1.35,0.8 2,0.8 C2.65,0.8 3.2,1.35 3.2,2 C3.2,2.65 2.65,3.2 2,3.2 Z M5,13.2 C4.34,13.2 3.8,12.65 3.8,12 C3.8,11.35 4.35,10.8 5,10.8 C5.65,10.8 6.2,11.35 6.2,12 C6.2,12.65 5.65,13.2 5,13.2 Z M8,3.2 C7.34,3.2 6.8,2.65 6.8,2 C6.8,1.35 7.35,0.8 8,0.8 C8.65,0.8 9.2,1.35 9.2,2 C9.2,2.65 8.65,3.2 8,3.2 Z"></path></svg></span></span></li>
</ul>
<h4><a href="#feature-detection-and-extraction" aria-hidden="true" class="anchor" id="user-content-feature-detection-and-extraction"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Feature Detection and Extraction</h4>
<ul>
<li><a target="_blank" rel="nofollow" href="http://www.vlfeat.org/">VLFeat</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.cs.ubc.ca/%7Elowe/keypoints/">SIFT</a>
<ul>
<li>David G. Lowe, "Distinctive image features from scale-invariant keypoints," International Journal of Computer Vision, 60, 2 (2004), pp. 91-110.</li>
</ul>
</li>
<li><a target="_blank" rel="nofollow" href="http://www.robots.ox.ac.uk/%7Evedaldi/code/siftpp.html">SIFT++</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.asl.ethz.ch/people/lestefan/personal/BRISK">BRISK</a>
<ul>
<li>Stefan Leutenegger, Margarita Chli and Roland Siegwart, "BRISK: Binary Robust Invariant Scalable Keypoints", ICCV 2011</li>
</ul>
</li>
<li><a target="_blank" rel="nofollow" href="http://www.vision.ee.ethz.ch/%7Esurf/">SURF</a>
<ul>
<li>Herbert Bay, Andreas Ess, Tinne Tuytelaars, Luc Van Gool, "SURF: Speeded Up Robust Features", Computer Vision and Image Understanding (CVIU), Vol. 110, No. 3, pp. 346--359, 2008</li>
</ul>
</li>
<li><a target="_blank" rel="nofollow" href="http://www.ivpe.com/freak.htm">FREAK</a>
<ul>
<li>A. Alahi, R. Ortiz, and P. Vandergheynst, "FREAK: Fast Retina Keypoint", CVPR 2012</li>
</ul>
</li>
<li><a target="_blank" rel="nofollow" href="http://www.robesafe.com/personal/pablo.alcantarilla/kaze.html">AKAZE</a>
<ul>
<li>Pablo F. Alcantarilla, Adrien Bartoli and Andrew J. Davison, "KAZE Features", ECCV 2012</li>
</ul>
</li>
<li><a id="user-content-nourani/LBP" target="_blank" rel="noopener noreferrer" href="https://github.com/nourani/LBP">Local Binary Patterns</a><span class="ml-1 text-grey-dark whitespace-no-wrap"><span class="text-grey-dark">14 <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 14 13" width="14" height="12" class="mr-1"><polygon points="14 5 9.1 4.36 7 0 4.9 4.36 0 5 3.6 8.26 2.67 13 7 10.67 11.33 13 10.4 8.26"></polygon></svg></span><span class="text-grey-dark">10 <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 14" width="10" height="12"><path d="M8,-8.47032947e-22 C7.09660216,-0.00238695453 6.3045861,0.603179379 6.07006224,1.47560813 C5.83553838,2.34803688 6.21717019,3.26909995 7,3.72 L7,5 L5,7 L3,5 L3,3.72 C3.78282981,3.26909995 4.16446162,2.34803688 3.92993776,1.47560813 C3.6954139,0.603179379 2.90339784,-0.00238695453 2,-4.44088363e-16 C1.09660216,-0.00238695453 0.304586097,0.603179379 0.0700622397,1.47560813 C-0.164461618,2.34803688 0.217170191,3.26909995 1,3.72 L1,5.5 L4,8.5 L4,10.28 C3.21717019,10.7309 2.83553838,11.6519631 3.07006224,12.5243919 C3.3045861,13.3968206 4.09660216,14.002387 5,14 C5.90339784,14.002387 6.6954139,13.3968206 6.92993776,12.5243919 C7.16446162,11.6519631 6.78282981,10.7309 6,10.28 L6,8.5 L9,5.5 L9,3.72 C9.78282981,3.26909995 10.1644616,2.34803688 9.92993776,1.47560813 C9.6954139,0.603179379 8.90339784,-0.00238695453 8,-8.47032947e-22 Z M2,3.2 C1.34,3.2 0.8,2.65 0.8,2 C0.8,1.35 1.35,0.8 2,0.8 C2.65,0.8 3.2,1.35 3.2,2 C3.2,2.65 2.65,3.2 2,3.2 Z M5,13.2 C4.34,13.2 3.8,12.65 3.8,12 C3.8,11.35 4.35,10.8 5,10.8 C5.65,10.8 6.2,11.35 6.2,12 C6.2,12.65 5.65,13.2 5,13.2 Z M8,3.2 C7.34,3.2 6.8,2.65 6.8,2 C6.8,1.35 7.35,0.8 8,0.8 C8.65,0.8 9.2,1.35 9.2,2 C9.2,2.65 8.65,3.2 8,3.2 Z"></path></svg></span></span></li>
</ul>
<h4><a href="#high-dynamic-range-imaging" aria-hidden="true" class="anchor" id="user-content-high-dynamic-range-imaging"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>High Dynamic Range Imaging</h4>
<ul>
<li><a id="user-content-banterle/HDR_Toolbox" target="_blank" rel="noopener noreferrer" href="https://github.com/banterle/HDR_Toolbox">HDR_Toolbox</a><span class="ml-1 text-grey-dark whitespace-no-wrap"><span class="text-orange-dark">57 <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 14 13" width="14" height="12" class="mr-1"><polygon points="14 5 9.1 4.36 7 0 4.9 4.36 0 5 3.6 8.26 2.67 13 7 10.67 11.33 13 10.4 8.26"></polygon></svg></span><span class="text-green-dark">29 <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 14" width="10" height="12"><path d="M8,-8.47032947e-22 C7.09660216,-0.00238695453 6.3045861,0.603179379 6.07006224,1.47560813 C5.83553838,2.34803688 6.21717019,3.26909995 7,3.72 L7,5 L5,7 L3,5 L3,3.72 C3.78282981,3.26909995 4.16446162,2.34803688 3.92993776,1.47560813 C3.6954139,0.603179379 2.90339784,-0.00238695453 2,-4.44088363e-16 C1.09660216,-0.00238695453 0.304586097,0.603179379 0.0700622397,1.47560813 C-0.164461618,2.34803688 0.217170191,3.26909995 1,3.72 L1,5.5 L4,8.5 L4,10.28 C3.21717019,10.7309 2.83553838,11.6519631 3.07006224,12.5243919 C3.3045861,13.3968206 4.09660216,14.002387 5,14 C5.90339784,14.002387 6.6954139,13.3968206 6.92993776,12.5243919 C7.16446162,11.6519631 6.78282981,10.7309 6,10.28 L6,8.5 L9,5.5 L9,3.72 C9.78282981,3.26909995 10.1644616,2.34803688 9.92993776,1.47560813 C9.6954139,0.603179379 8.90339784,-0.00238695453 8,-8.47032947e-22 Z M2,3.2 C1.34,3.2 0.8,2.65 0.8,2 C0.8,1.35 1.35,0.8 2,0.8 C2.65,0.8 3.2,1.35 3.2,2 C3.2,2.65 2.65,3.2 2,3.2 Z M5,13.2 C4.34,13.2 3.8,12.65 3.8,12 C3.8,11.35 4.35,10.8 5,10.8 C5.65,10.8 6.2,11.35 6.2,12 C6.2,12.65 5.65,13.2 5,13.2 Z M8,3.2 C7.34,3.2 6.8,2.65 6.8,2 C6.8,1.35 7.35,0.8 8,0.8 C8.65,0.8 9.2,1.35 9.2,2 C9.2,2.65 8.65,3.2 8,3.2 Z"></path></svg></span></span></li>
</ul>
<h4><a href="#semantic-segmentation" aria-hidden="true" class="anchor" id="user-content-semantic-segmentation"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Semantic Segmentation</h4>
<ul>
<li><a target="_blank" rel="nofollow" href="http://www.it-caesar.com/list-of-contemporary-semantic-segmentation-datasets/">List of Semantic Segmentation algorithms</a></li>
</ul>
<h4><a href="#low-level-vision" aria-hidden="true" class="anchor" id="user-content-low-level-vision"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Low-level Vision</h4>
<h6><a href="#stereo-vision" aria-hidden="true" class="anchor" id="user-content-stereo-vision"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Stereo Vision</h6>
<ul>
<li><a target="_blank" rel="nofollow" href="http://vision.middlebury.edu/stereo/">Middlebury Stereo Vision</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.cvlibs.net/datasets/kitti/eval_stereo_flow.php?benchmark=stero">The KITTI Vision Benchmark Suite</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.cvlibs.net/software/libelas/">LIBELAS: Library for Efficient Large-scale Stereo Matching</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.6d-vision.com/ground-truth-stixel-dataset">Ground Truth Stixel Dataset</a></li>
</ul>
<h6><a href="#optical-flow" aria-hidden="true" class="anchor" id="user-content-optical-flow"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Optical Flow</h6>
<ul>
<li><a target="_blank" rel="nofollow" href="http://vision.middlebury.edu/flow/">Middlebury Optical Flow Evaluation</a></li>
<li><a target="_blank" rel="nofollow" href="http://sintel.is.tue.mpg.de/">MPI-Sintel Optical Flow Dataset and Evaluation</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.cvlibs.net/datasets/kitti/eval_stereo_flow.php?benchmark=flow">The KITTI Vision Benchmark Suite</a></li>
<li><a target="_blank" rel="nofollow" href="http://hci.iwr.uni-heidelberg.de/Benchmarks/document/Challenging_Data_for_Stereo_and_Optical_Flow/">HCI Challenge</a></li>
<li><a target="_blank" rel="nofollow" href="http://people.csail.mit.edu/celiu/OpticalFlow/">Coarse2Fine Optical Flow</a> - Ce Liu (MIT)</li>
<li><a target="_blank" rel="nofollow" href="http://cs.brown.edu/%7Edqsun/code/cvpr10_flow_code.zip">Secrets of Optical Flow Estimation and Their Principles</a></li>
<li><a target="_blank" rel="nofollow" href="http://people.csail.mit.edu/celiu/OpticalFlow/">C++/MatLab Optical Flow by C. Liu (based on Brox et al. and Bruhn et al.)</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.ctim.es/research_works/parallel_robust_optical_flow/">Parallel Robust Optical Flow by Sánchez Pérez et al.</a></li>
</ul>
<h6><a href="#image-denoising" aria-hidden="true" class="anchor" id="user-content-image-denoising"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Image Denoising</h6>
<p>BM3D, KSVD,</p>
<h6><a href="#super-resolution" aria-hidden="true" class="anchor" id="user-content-super-resolution"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Super-resolution</h6>
<ul>
<li><a target="_blank" rel="nofollow" href="http://www.robots.ox.ac.uk/%7Evgg/software/SR/">Multi-frame image super-resolution</a>
<ul>
<li>Pickup, L. C. Machine Learning in Multi-frame Image Super-resolution, PhD thesis 2008</li>
</ul>
</li>
<li><a target="_blank" rel="nofollow" href="http://people.csail.mit.edu/billf/project%20pages/sresCode/Markov%20Random%20Fields%20for%20Super-Resolution.html">Markov Random Fields for Super-Resolution</a>
<ul>
<li>W. T Freeman and C. Liu. Markov Random Fields for Super-resolution and Texture Synthesis. In A. Blake, P. Kohli, and C. Rother, eds., Advances in Markov Random Fields for Vision and Image Processing, Chapter 10. MIT Press, 2011</li>
</ul>
</li>
<li><a target="_blank" rel="nofollow" href="https://people.mpi-inf.mpg.de/%7Ekkim/supres/supres.htm">Sparse regression and natural image prior</a>
<ul>
<li>K. I. Kim and Y. Kwon, "Single-image super-resolution using sparse regression and natural image prior", IEEE Trans. Pattern Analysis and Machine Intelligence, vol. 32, no. 6, pp. 1127-1133, 2010.</li>
</ul>
</li>
<li><a target="_blank" rel="nofollow" href="http://www.cs.technion.ac.il/%7Eelad/Various/SingleImageSR_TIP14_Box.zip">Single-Image Super Resolution via a Statistical Model</a>
<ul>
<li>T. Peleg and M. Elad, A Statistical Prediction Model Based on Sparse Representations for Single Image Super-Resolution, IEEE Transactions on Image Processing, Vol. 23, No. 6, Pages 2569-2582, June 2014</li>
</ul>
</li>
<li><a target="_blank" rel="nofollow" href="http://www.cs.technion.ac.il/%7Eelad/Various/Single_Image_SR.zip">Sparse Coding for Super-Resolution</a>
<ul>
<li>R. Zeyde, M. Elad, and M. Protter On Single Image Scale-Up using Sparse-Representations, Curves &amp; Surfaces, Avignon-France, June 24-30, 2010 (appears also in Lecture-Notes-on-Computer-Science - LNCS).</li>
</ul>
</li>
<li><a target="_blank" rel="nofollow" href="http://www.ifp.illinois.edu/%7Ejyang29/ScSR.htm">Patch-wise Sparse Recovery</a>
<ul>
<li>Jianchao Yang, John Wright, Thomas Huang, and Yi Ma. Image super-resolution via sparse representation. IEEE Transactions on Image Processing (TIP), vol. 19, issue 11, 2010.</li>
</ul>
</li>
<li><a target="_blank" rel="nofollow" href="http://www.jdl.ac.cn/user/hchang/doc/code.rar">Neighbor embedding</a>
<ul>
<li>H. Chang, D.Y. Yeung, Y. Xiong. Super-resolution through neighbor embedding. Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR), vol.1, pp.275-282, Washington, DC, USA, 27 June - 2 July 2004.</li>
</ul>
</li>
<li><a target="_blank" rel="nofollow" href="https://sites.google.com/site/yuzhushome/single-image-super-resolution-using-deformable-patches">Deformable Patches</a>
<ul>
<li>Yu Zhu, Yanning Zhang and Alan Yuille, Single Image Super-resolution using Deformable Patches, CVPR 2014</li>
</ul>
</li>
<li><a target="_blank" rel="nofollow" href="http://mmlab.ie.cuhk.edu.hk/projects/SRCNN.html">SRCNN</a>
<ul>
<li>Chao Dong, Chen Change Loy, Kaiming He, Xiaoou Tang, Learning a Deep Convolutional Network for Image Super-Resolution, in ECCV 2014</li>
</ul>
</li>
<li><a target="_blank" rel="nofollow" href="http://www.vision.ee.ethz.ch/%7Etimofter/ACCV2014_ID820_SUPPLEMENTARY/index.html">A+: Adjusted Anchored Neighborhood Regression</a>
<ul>
<li>R. Timofte, V. De Smet, and L. Van Gool. A+: Adjusted Anchored Neighborhood Regression for Fast Super-Resolution, ACCV 2014</li>
</ul>
</li>
<li><a target="_blank" rel="nofollow" href="https://sites.google.com/site/jbhuang0604/publications/struct_sr">Transformed Self-Exemplars</a>
<ul>
<li>Jia-Bin Huang, Abhishek Singh, and Narendra Ahuja, Single Image Super-Resolution using Transformed Self-Exemplars, IEEE Conference on Computer Vision and Pattern Recognition, 2015</li>
</ul>
</li>
</ul>
<h6><a href="#image-deblurring" aria-hidden="true" class="anchor" id="user-content-image-deblurring"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Image Deblurring</h6>
<p>Non-blind deconvolution</p>
<ul>
<li><a target="_blank" rel="nofollow" href="http://homes.cs.washington.edu/%7Eshanqi/work/spvdeconv/">Spatially variant non-blind deconvolution</a></li>
<li><a target="_blank" rel="nofollow" href="http://cg.postech.ac.kr/research/deconv_outliers/">Handling Outliers in Non-blind Image Deconvolution</a></li>
<li><a target="_blank" rel="nofollow" href="http://cs.nyu.edu/%7Edilip/research/fast-deconvolution/">Hyper-Laplacian Priors</a></li>
<li><a target="_blank" rel="nofollow" href="http://people.csail.mit.edu/danielzoran/epllcode.zip">From Learning Models of Natural Image Patches to Whole Image Restoration</a></li>
<li><a target="_blank" rel="nofollow" href="http://lxu.me/projects/dcnn/">Deep Convolutional Neural Network for Image Deconvolution</a></li>
<li><a target="_blank" rel="nofollow" href="http://webdav.is.mpg.de/pixel/neural_deconvolution/">Neural Deconvolution</a></li>
</ul>
<p>Blind deconvolution</p>
<ul>
<li><a target="_blank" rel="nofollow" href="http://www.cs.nyu.edu/%7Efergus/research/deblur.html">Removing Camera Shake From A Single Photograph</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.cse.cuhk.edu.hk/leojia/projects/motion_deblurring/">High-quality motion deblurring from a single image</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.cse.cuhk.edu.hk/leojia/projects/robust_deblur/">Two-Phase Kernel Estimation for Robust Motion Deblurring</a></li>
<li><a target="_blank" rel="nofollow" href="http://people.csail.mit.edu/taegsang/Documents/RadonDeblurringCode.zip">Blur kernel estimation using the radon transform</a></li>
<li><a target="_blank" rel="nofollow" href="http://cg.postech.ac.kr/research/fast_motion_deblurring/">Fast motion deblurring</a></li>
<li><a target="_blank" rel="nofollow" href="http://cs.nyu.edu//%7Edilip/research/blind-deconvolution/">Blind Deconvolution Using a Normalized Sparsity Measure</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.cs.huji.ac.il/%7Eraananf/projects/deblur/">Blur-kernel estimation from spectral irregularities</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.wisdom.weizmann.ac.il/%7Elevina/papers/LevinEtalCVPR2011Code.zip">Efficient marginal likelihood optimization in blind deconvolution</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.cse.cuhk.edu.hk/leojia/projects/l0deblur/">Unnatural L0 Sparse Representation for Natural Image Deblurring</a></li>
<li><a target="_blank" rel="nofollow" href="http://cs.brown.edu/%7Elbsun/deblur2013/deblur2013iccp.html">Edge-based Blur Kernel Estimation Using Patch Priors</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.wisdom.weizmann.ac.il/%7Evision/BlindDeblur.html">Blind Deblurring Using Internal Patch Recurrence</a></li>
</ul>
<p>Non-uniform Deblurring</p>
<ul>
<li><a target="_blank" rel="nofollow" href="http://www.di.ens.fr/willow/research/deblurring/">Non-uniform Deblurring for Shaken Images</a></li>
<li><a target="_blank" rel="nofollow" href="http://grail.cs.washington.edu/projects/mdf_deblurring/">Single Image Deblurring Using Motion Density Functions</a></li>
<li><a target="_blank" rel="nofollow" href="http://research.microsoft.com/en-us/um/redmond/groups/ivm/imudeblurring/">Image Deblurring using Inertial Measurement Sensors</a></li>
<li><a target="_blank" rel="nofollow" href="http://webdav.is.mpg.de/pixel/fast_removal_of_camera_shake/">Fast Removal of Non-uniform Camera Shake</a></li>
</ul>
<h6><a href="#image-completion" aria-hidden="true" class="anchor" id="user-content-image-completion"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Image Completion</h6>
<ul>
<li><a target="_blank" rel="nofollow" href="http://registry.gimp.org/node/27986">GIMP Resynthesizer</a></li>
<li><a target="_blank" rel="nofollow" href="http://lafarren.com/image-completer/">Priority BP</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.ece.ucsb.edu/%7Epsen/melding">ImageMelding</a></li>
<li><a target="_blank" rel="nofollow" href="https://sites.google.com/site/jbhuang0604/publications/struct_completion">PlanarStructureCompletion</a></li>
</ul>
<h6><a href="#image-retargeting" aria-hidden="true" class="anchor" id="user-content-image-retargeting"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Image Retargeting</h6>
<ul>
<li><a target="_blank" rel="nofollow" href="http://people.csail.mit.edu/mrub/retargetme/">RetargetMe</a></li>
</ul>
<h6><a href="#alpha-matting" aria-hidden="true" class="anchor" id="user-content-alpha-matting"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Alpha Matting</h6>
<ul>
<li><a target="_blank" rel="nofollow" href="http://www.alphamatting.com/">Alpha Matting Evaluation</a></li>
<li><a target="_blank" rel="nofollow" href="http://people.csail.mit.edu/alevin/matting.tar.gz">Closed-form image matting</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.vision.huji.ac.il/SpectralMatting/">Spectral Matting</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.mathworks.com/matlabcentral/fileexchange/31412-learning-based-digital-matting">Learning-based Matting</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.alphamatting.com/ImprovingMattingComprehensiveSamplingSets_CVPR2013.zip">Improving Image Matting using Comprehensive Sampling Sets</a></li>
</ul>
<h6><a href="#image-pyramid" aria-hidden="true" class="anchor" id="user-content-image-pyramid"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Image Pyramid</h6>
<ul>
<li><a target="_blank" rel="nofollow" href="http://www.cns.nyu.edu/%7Eeero/steerpyr/">The Steerable Pyramid</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.curvelet.org/">CurveLab</a></li>
</ul>
<h6><a href="#edge-preserving-image-processing" aria-hidden="true" class="anchor" id="user-content-edge-preserving-image-processing"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Edge-preserving image processing</h6>
<ul>
<li><a target="_blank" rel="nofollow" href="http://people.csail.mit.edu/sparis/bf/">Fast Bilateral Filter</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.cs.cityu.edu.hk/%7Eqiyang/publications/code/qx.cvpr09.ctbf.zip">O(1) Bilateral Filter</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.cs.cityu.edu.hk/%7Eqiyang/publications/eccv-12/">Recursive Bilateral Filtering</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.cse.cuhk.edu.hk/leojia/projects/rollguidance/">Rolling Guidance Filter</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.cse.cuhk.edu.hk/leojia/projects/texturesep/index.html">Relative Total Variation</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.cse.cuhk.edu.hk/leojia/projects/L0smoothing/index.html">L0 Gradient Optimization</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.inf.ufrgs.br/%7Eeslgastal/DomainTransform/">Domain Transform</a></li>
<li><a target="_blank" rel="nofollow" href="http://inf.ufrgs.br/%7Eeslgastal/AdaptiveManifolds/">Adaptive Manifold</a></li>
<li><a target="_blank" rel="nofollow" href="http://research.microsoft.com/en-us/um/people/kahe/eccv10/">Guided image filtering</a></li>
</ul>
<h4><a href="#intrinsic-images" aria-hidden="true" class="anchor" id="user-content-intrinsic-images"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Intrinsic Images</h4>
<ul>
<li><a target="_blank" rel="nofollow" href="http://people.tuebingen.mpg.de/mkiefel/projects/intrinsic/">Recovering Intrinsic Images with a global Sparsity Prior on Reflectance</a></li>
<li><a target="_blank" rel="nofollow" href="http://giga.cps.unizar.es/%7Eelenag/projects/EGSR2012_intrinsic/">Intrinsic Images by Clustering</a></li>
</ul>
<h4><a href="#contour-detection-and-image-segmentation" aria-hidden="true" class="anchor" id="user-content-contour-detection-and-image-segmentation"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Contour Detection and Image Segmentation</h4>
<ul>
<li><a target="_blank" rel="nofollow" href="http://coewww.rutgers.edu/riul/research/code/EDISON/">Mean Shift Segmentation</a></li>
<li><a target="_blank" rel="nofollow" href="http://cs.brown.edu/%7Epff/segment/">Graph-based Segmentation</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.cis.upenn.edu/%7Ejshi/software/">Normalized Cut</a></li>
<li><a target="_blank" rel="nofollow" href="http://grabcut.weebly.com/background--algorithm.html">Grab Cut</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/resources.html">Contour Detection and Image Segmentation</a></li>
<li><a target="_blank" rel="nofollow" href="http://research.microsoft.com/en-us/downloads/389109f6-b4e8-404c-84bf-239f7cbf4e3d/">Structured Edge Detection</a></li>
<li><a target="_blank" rel="nofollow" href="http://web.mit.edu/phillipi/pmi-boundaries/">Pointwise Mutual Information</a></li>
<li><a target="_blank" rel="nofollow" href="http://ivrl.epfl.ch/research/superpixels">SLIC Super-pixel</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.vlfeat.org/overview/quickshift.html">QuickShift</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.cs.toronto.edu/%7Ebabalex/research.html">TurboPixels</a></li>
<li><a target="_blank" rel="nofollow" href="http://mingyuliu.net/">Entropy Rate Superpixel</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.vsi.cs.uni-frankfurt.de/research/current-projects/research/superpixel-segmentation/">Contour Relaxed Superpixels</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.mvdblive.org/seeds/">SEEDS</a></li>
<li><a id="user-content-davidstutz/seeds-revised" target="_blank" rel="noopener noreferrer" href="https://github.com/davidstutz/seeds-revised">SEEDS Revised</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/mcg/">Multiscale Combinatorial Grouping</a></li>
<li><a id="user-content-pdollar/edges" target="_blank" rel="noopener noreferrer" href="https://github.com/pdollar/edges">Fast Edge Detection Using Structured Forests</a><span class="ml-1 text-grey-dark whitespace-no-wrap"><span class="text-grey-dark">19 <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 14 13" width="14" height="12" class="mr-1"><polygon points="14 5 9.1 4.36 7 0 4.9 4.36 0 5 3.6 8.26 2.67 13 7 10.67 11.33 13 10.4 8.26"></polygon></svg></span><span class="text-grey-dark">10 <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 14" width="10" height="12"><path d="M8,-8.47032947e-22 C7.09660216,-0.00238695453 6.3045861,0.603179379 6.07006224,1.47560813 C5.83553838,2.34803688 6.21717019,3.26909995 7,3.72 L7,5 L5,7 L3,5 L3,3.72 C3.78282981,3.26909995 4.16446162,2.34803688 3.92993776,1.47560813 C3.6954139,0.603179379 2.90339784,-0.00238695453 2,-4.44088363e-16 C1.09660216,-0.00238695453 0.304586097,0.603179379 0.0700622397,1.47560813 C-0.164461618,2.34803688 0.217170191,3.26909995 1,3.72 L1,5.5 L4,8.5 L4,10.28 C3.21717019,10.7309 2.83553838,11.6519631 3.07006224,12.5243919 C3.3045861,13.3968206 4.09660216,14.002387 5,14 C5.90339784,14.002387 6.6954139,13.3968206 6.92993776,12.5243919 C7.16446162,11.6519631 6.78282981,10.7309 6,10.28 L6,8.5 L9,5.5 L9,3.72 C9.78282981,3.26909995 10.1644616,2.34803688 9.92993776,1.47560813 C9.6954139,0.603179379 8.90339784,-0.00238695453 8,-8.47032947e-22 Z M2,3.2 C1.34,3.2 0.8,2.65 0.8,2 C0.8,1.35 1.35,0.8 2,0.8 C2.65,0.8 3.2,1.35 3.2,2 C3.2,2.65 2.65,3.2 2,3.2 Z M5,13.2 C4.34,13.2 3.8,12.65 3.8,12 C3.8,11.35 4.35,10.8 5,10.8 C5.65,10.8 6.2,11.35 6.2,12 C6.2,12.65 5.65,13.2 5,13.2 Z M8,3.2 C7.34,3.2 6.8,2.65 6.8,2 C6.8,1.35 7.35,0.8 8,0.8 C8.65,0.8 9.2,1.35 9.2,2 C9.2,2.65 8.65,3.2 8,3.2 Z"></path></svg></span></span></li>
</ul>
<h4><a href="#interactive-image-segmentation" aria-hidden="true" class="anchor" id="user-content-interactive-image-segmentation"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Interactive Image Segmentation</h4>
<ul>
<li><a target="_blank" rel="nofollow" href="http://cns.bu.edu/%7Elgrady/software.html">Random Walker</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.tc.umn.edu/%7Ebaixx015/">Geodesic Segmentation</a></li>
<li><a target="_blank" rel="nofollow" href="http://research.microsoft.com/apps/pubs/default.aspx?id=69040">Lazy Snapping</a></li>
<li><a target="_blank" rel="nofollow" href="http://powerwatershed.sourceforge.net/">Power Watershed</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.adobe.com/technology/people/san-jose/brian-price.html">Geodesic Graph Cut</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.cs.cmu.edu/%7Eolivierd/">Segmentation by Transduction</a></li>
</ul>
<h4><a href="#video-segmentation" aria-hidden="true" class="anchor" id="user-content-video-segmentation"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Video Segmentation</h4>
<ul>
<li><a target="_blank" rel="nofollow" href="http://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/research/image-and-video-segmentation/video-segmentation-with-superpixels/">Video Segmentation with Superpixels</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.cc.gatech.edu/cpl/projects/videosegmentation/">Efficient hierarchical graph-based video segmentation</a></li>
<li><a target="_blank" rel="nofollow" href="http://lmb.informatik.uni-freiburg.de/Publications/2011/OB11/">Object segmentation in video</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.cse.buffalo.edu/%7Ejcorso/r/supervoxels/">Streaming hierarchical video segmentation</a></li>
</ul>
<h4><a href="#camera-calibration" aria-hidden="true" class="anchor" id="user-content-camera-calibration"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Camera calibration</h4>
<ul>
<li><a target="_blank" rel="nofollow" href="http://www.vision.caltech.edu/bouguetj/calib_doc/">Camera Calibration Toolbox for Matlab</a></li>
<li><a target="_blank" rel="nofollow" href="http://docs.opencv.org/trunk/doc/tutorials/calib3d/camera_calibration/camera_calibration.html#">Camera calibration With OpenCV</a></li>
<li><a target="_blank" rel="nofollow" href="https://sites.google.com/site/prclibo/toolbox">Multiple Camera Calibration Toolbox</a></li>
</ul>
<h4><a href="#simultaneous-localization-and-mapping" aria-hidden="true" class="anchor" id="user-content-simultaneous-localization-and-mapping"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Simultaneous localization and mapping</h4>
<h6><a href="#slam-community" aria-hidden="true" class="anchor" id="user-content-slam-community"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>SLAM community:</h6>
<ul>
<li><a target="_blank" rel="nofollow" href="https://www.openslam.org/">openSLAM</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.cvlibs.net/datasets/kitti/eval_odometry.php">Kitti Odometry: benchmark for outdoor visual odometry (codes may be available)</a></li>
</ul>
<h6><a href="#trackingodometry" aria-hidden="true" class="anchor" id="user-content-trackingodometry"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Tracking/Odometry:</h6>
<ul>
<li><a target="_blank" rel="nofollow" href="http://www.cvlibs.net/software/libviso/">LIBVISO2: C++ Library for Visual Odometry 2</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.robots.ox.ac.uk/%7Egk/PTAM/">PTAM: Parallel tracking and mapping</a></li>
<li><a id="user-content-GerhardR/kfusion" target="_blank" rel="noopener noreferrer" href="https://github.com/GerhardR/kfusion">KFusion: Implementation of KinectFusion</a><span class="ml-1 text-grey-dark whitespace-no-wrap"><span class="text-orange-dark">26 <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 14 13" width="14" height="12" class="mr-1"><polygon points="14 5 9.1 4.36 7 0 4.9 4.36 0 5 3.6 8.26 2.67 13 7 10.67 11.33 13 10.4 8.26"></polygon></svg></span><span class="text-grey-dark">19 <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 14" width="10" height="12"><path d="M8,-8.47032947e-22 C7.09660216,-0.00238695453 6.3045861,0.603179379 6.07006224,1.47560813 C5.83553838,2.34803688 6.21717019,3.26909995 7,3.72 L7,5 L5,7 L3,5 L3,3.72 C3.78282981,3.26909995 4.16446162,2.34803688 3.92993776,1.47560813 C3.6954139,0.603179379 2.90339784,-0.00238695453 2,-4.44088363e-16 C1.09660216,-0.00238695453 0.304586097,0.603179379 0.0700622397,1.47560813 C-0.164461618,2.34803688 0.217170191,3.26909995 1,3.72 L1,5.5 L4,8.5 L4,10.28 C3.21717019,10.7309 2.83553838,11.6519631 3.07006224,12.5243919 C3.3045861,13.3968206 4.09660216,14.002387 5,14 C5.90339784,14.002387 6.6954139,13.3968206 6.92993776,12.5243919 C7.16446162,11.6519631 6.78282981,10.7309 6,10.28 L6,8.5 L9,5.5 L9,3.72 C9.78282981,3.26909995 10.1644616,2.34803688 9.92993776,1.47560813 C9.6954139,0.603179379 8.90339784,-0.00238695453 8,-8.47032947e-22 Z M2,3.2 C1.34,3.2 0.8,2.65 0.8,2 C0.8,1.35 1.35,0.8 2,0.8 C2.65,0.8 3.2,1.35 3.2,2 C3.2,2.65 2.65,3.2 2,3.2 Z M5,13.2 C4.34,13.2 3.8,12.65 3.8,12 C3.8,11.35 4.35,10.8 5,10.8 C5.65,10.8 6.2,11.35 6.2,12 C6.2,12.65 5.65,13.2 5,13.2 Z M8,3.2 C7.34,3.2 6.8,2.65 6.8,2 C6.8,1.35 7.35,0.8 8,0.8 C8.65,0.8 9.2,1.35 9.2,2 C9.2,2.65 8.65,3.2 8,3.2 Z"></path></svg></span></span></li>
<li><a id="user-content-Nerei/kinfu_remake" target="_blank" rel="noopener noreferrer" href="https://github.com/Nerei/kinfu_remake">kinfu_remake: Lightweight, reworked and optimized version of Kinfu.</a><span class="ml-1 text-grey-dark whitespace-no-wrap"><span class="text-orange-dark">96 <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 14 13" width="14" height="12" class="mr-1"><polygon points="14 5 9.1 4.36 7 0 4.9 4.36 0 5 3.6 8.26 2.67 13 7 10.67 11.33 13 10.4 8.26"></polygon></svg></span><span class="text-green-dark">60 <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 14" width="10" height="12"><path d="M8,-8.47032947e-22 C7.09660216,-0.00238695453 6.3045861,0.603179379 6.07006224,1.47560813 C5.83553838,2.34803688 6.21717019,3.26909995 7,3.72 L7,5 L5,7 L3,5 L3,3.72 C3.78282981,3.26909995 4.16446162,2.34803688 3.92993776,1.47560813 C3.6954139,0.603179379 2.90339784,-0.00238695453 2,-4.44088363e-16 C1.09660216,-0.00238695453 0.304586097,0.603179379 0.0700622397,1.47560813 C-0.164461618,2.34803688 0.217170191,3.26909995 1,3.72 L1,5.5 L4,8.5 L4,10.28 C3.21717019,10.7309 2.83553838,11.6519631 3.07006224,12.5243919 C3.3045861,13.3968206 4.09660216,14.002387 5,14 C5.90339784,14.002387 6.6954139,13.3968206 6.92993776,12.5243919 C7.16446162,11.6519631 6.78282981,10.7309 6,10.28 L6,8.5 L9,5.5 L9,3.72 C9.78282981,3.26909995 10.1644616,2.34803688 9.92993776,1.47560813 C9.6954139,0.603179379 8.90339784,-0.00238695453 8,-8.47032947e-22 Z M2,3.2 C1.34,3.2 0.8,2.65 0.8,2 C0.8,1.35 1.35,0.8 2,0.8 C2.65,0.8 3.2,1.35 3.2,2 C3.2,2.65 2.65,3.2 2,3.2 Z M5,13.2 C4.34,13.2 3.8,12.65 3.8,12 C3.8,11.35 4.35,10.8 5,10.8 C5.65,10.8 6.2,11.35 6.2,12 C6.2,12.65 5.65,13.2 5,13.2 Z M8,3.2 C7.34,3.2 6.8,2.65 6.8,2 C6.8,1.35 7.35,0.8 8,0.8 C8.65,0.8 9.2,1.35 9.2,2 C9.2,2.65 8.65,3.2 8,3.2 Z"></path></svg></span></span></li>
<li><a target="_blank" rel="nofollow" href="http://las-vegas.uni-osnabrueck.de/related-projects/lvr-kinfu/">LVR-KinFu: kinfu_remake based Large Scale KinectFusion with online reconstruction</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.robots.ox.ac.uk/%7Evictor/infinitam/">InfiniTAM: Implementation of multi-platform large-scale depth tracking and fusion</a></li>
<li><a id="user-content-nachtmar/VoxelHashing" target="_blank" rel="noopener noreferrer" href="https://github.com/nachtmar/VoxelHashing">VoxelHashing: Large-scale KinectFusion</a><span class="ml-1 text-grey-dark whitespace-no-wrap"><span class="text-grey-dark">6 <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 14 13" width="14" height="12" class="mr-1"><polygon points="14 5 9.1 4.36 7 0 4.9 4.36 0 5 3.6 8.26 2.67 13 7 10.67 11.33 13 10.4 8.26"></polygon></svg></span><span class="text-grey-dark">10 <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 14" width="10" height="12"><path d="M8,-8.47032947e-22 C7.09660216,-0.00238695453 6.3045861,0.603179379 6.07006224,1.47560813 C5.83553838,2.34803688 6.21717019,3.26909995 7,3.72 L7,5 L5,7 L3,5 L3,3.72 C3.78282981,3.26909995 4.16446162,2.34803688 3.92993776,1.47560813 C3.6954139,0.603179379 2.90339784,-0.00238695453 2,-4.44088363e-16 C1.09660216,-0.00238695453 0.304586097,0.603179379 0.0700622397,1.47560813 C-0.164461618,2.34803688 0.217170191,3.26909995 1,3.72 L1,5.5 L4,8.5 L4,10.28 C3.21717019,10.7309 2.83553838,11.6519631 3.07006224,12.5243919 C3.3045861,13.3968206 4.09660216,14.002387 5,14 C5.90339784,14.002387 6.6954139,13.3968206 6.92993776,12.5243919 C7.16446162,11.6519631 6.78282981,10.7309 6,10.28 L6,8.5 L9,5.5 L9,3.72 C9.78282981,3.26909995 10.1644616,2.34803688 9.92993776,1.47560813 C9.6954139,0.603179379 8.90339784,-0.00238695453 8,-8.47032947e-22 Z M2,3.2 C1.34,3.2 0.8,2.65 0.8,2 C0.8,1.35 1.35,0.8 2,0.8 C2.65,0.8 3.2,1.35 3.2,2 C3.2,2.65 2.65,3.2 2,3.2 Z M5,13.2 C4.34,13.2 3.8,12.65 3.8,12 C3.8,11.35 4.35,10.8 5,10.8 C5.65,10.8 6.2,11.35 6.2,12 C6.2,12.65 5.65,13.2 5,13.2 Z M8,3.2 C7.34,3.2 6.8,2.65 6.8,2 C6.8,1.35 7.35,0.8 8,0.8 C8.65,0.8 9.2,1.35 9.2,2 C9.2,2.65 8.65,3.2 8,3.2 Z"></path></svg></span></span></li>
<li><a target="_blank" rel="nofollow" href="http://apt.cs.manchester.ac.uk/projects/PAMELA/tools/SLAMBench/">SLAMBench: Multiple-implementation of KinectFusion</a></li>
<li><a id="user-content-uzh-rpg/rpg_svo" target="_blank" rel="noopener noreferrer" href="https://github.com/uzh-rpg/rpg_svo">SVO: Semi-direct visual odometry</a><span class="ml-1 text-grey-dark whitespace-no-wrap"><span class="text-orange-dark">713 <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 14 13" width="14" height="12" class="mr-1"><polygon points="14 5 9.1 4.36 7 0 4.9 4.36 0 5 3.6 8.26 2.67 13 7 10.67 11.33 13 10.4 8.26"></polygon></svg></span><span class="text-green-dark">408 <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 14" width="10" height="12"><path d="M8,-8.47032947e-22 C7.09660216,-0.00238695453 6.3045861,0.603179379 6.07006224,1.47560813 C5.83553838,2.34803688 6.21717019,3.26909995 7,3.72 L7,5 L5,7 L3,5 L3,3.72 C3.78282981,3.26909995 4.16446162,2.34803688 3.92993776,1.47560813 C3.6954139,0.603179379 2.90339784,-0.00238695453 2,-4.44088363e-16 C1.09660216,-0.00238695453 0.304586097,0.603179379 0.0700622397,1.47560813 C-0.164461618,2.34803688 0.217170191,3.26909995 1,3.72 L1,5.5 L4,8.5 L4,10.28 C3.21717019,10.7309 2.83553838,11.6519631 3.07006224,12.5243919 C3.3045861,13.3968206 4.09660216,14.002387 5,14 C5.90339784,14.002387 6.6954139,13.3968206 6.92993776,12.5243919 C7.16446162,11.6519631 6.78282981,10.7309 6,10.28 L6,8.5 L9,5.5 L9,3.72 C9.78282981,3.26909995 10.1644616,2.34803688 9.92993776,1.47560813 C9.6954139,0.603179379 8.90339784,-0.00238695453 8,-8.47032947e-22 Z M2,3.2 C1.34,3.2 0.8,2.65 0.8,2 C0.8,1.35 1.35,0.8 2,0.8 C2.65,0.8 3.2,1.35 3.2,2 C3.2,2.65 2.65,3.2 2,3.2 Z M5,13.2 C4.34,13.2 3.8,12.65 3.8,12 C3.8,11.35 4.35,10.8 5,10.8 C5.65,10.8 6.2,11.35 6.2,12 C6.2,12.65 5.65,13.2 5,13.2 Z M8,3.2 C7.34,3.2 6.8,2.65 6.8,2 C6.8,1.35 7.35,0.8 8,0.8 C8.65,0.8 9.2,1.35 9.2,2 C9.2,2.65 8.65,3.2 8,3.2 Z"></path></svg></span></span></li>
<li><a id="user-content-tum-vision/dvo_slam" target="_blank" rel="noopener noreferrer" href="https://github.com/tum-vision/dvo_slam">DVO: dense visual odometry</a><span class="ml-1 text-grey-dark whitespace-no-wrap"><span class="text-orange-dark">224 <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 14 13" width="14" height="12" class="mr-1"><polygon points="14 5 9.1 4.36 7 0 4.9 4.36 0 5 3.6 8.26 2.67 13 7 10.67 11.33 13 10.4 8.26"></polygon></svg></span><span class="text-green-dark">184 <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 14" width="10" height="12"><path d="M8,-8.47032947e-22 C7.09660216,-0.00238695453 6.3045861,0.603179379 6.07006224,1.47560813 C5.83553838,2.34803688 6.21717019,3.26909995 7,3.72 L7,5 L5,7 L3,5 L3,3.72 C3.78282981,3.26909995 4.16446162,2.34803688 3.92993776,1.47560813 C3.6954139,0.603179379 2.90339784,-0.00238695453 2,-4.44088363e-16 C1.09660216,-0.00238695453 0.304586097,0.603179379 0.0700622397,1.47560813 C-0.164461618,2.34803688 0.217170191,3.26909995 1,3.72 L1,5.5 L4,8.5 L4,10.28 C3.21717019,10.7309 2.83553838,11.6519631 3.07006224,12.5243919 C3.3045861,13.3968206 4.09660216,14.002387 5,14 C5.90339784,14.002387 6.6954139,13.3968206 6.92993776,12.5243919 C7.16446162,11.6519631 6.78282981,10.7309 6,10.28 L6,8.5 L9,5.5 L9,3.72 C9.78282981,3.26909995 10.1644616,2.34803688 9.92993776,1.47560813 C9.6954139,0.603179379 8.90339784,-0.00238695453 8,-8.47032947e-22 Z M2,3.2 C1.34,3.2 0.8,2.65 0.8,2 C0.8,1.35 1.35,0.8 2,0.8 C2.65,0.8 3.2,1.35 3.2,2 C3.2,2.65 2.65,3.2 2,3.2 Z M5,13.2 C4.34,13.2 3.8,12.65 3.8,12 C3.8,11.35 4.35,10.8 5,10.8 C5.65,10.8 6.2,11.35 6.2,12 C6.2,12.65 5.65,13.2 5,13.2 Z M8,3.2 C7.34,3.2 6.8,2.65 6.8,2 C6.8,1.35 7.35,0.8 8,0.8 C8.65,0.8 9.2,1.35 9.2,2 C9.2,2.65 8.65,3.2 8,3.2 Z"></path></svg></span></span></li>
<li><a target="_blank" rel="nofollow" href="https://code.google.com/p/fovis/">FOVIS: RGB-D visual odometry</a></li>
</ul>
<h6><a href="#graph-optimization" aria-hidden="true" class="anchor" id="user-content-graph-optimization"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Graph Optimization:</h6>
<ul>
<li><a target="_blank" rel="nofollow" href="https://collab.cc.gatech.edu/borg/gtsam?destination=node%2F299">GTSAM: General smoothing and mapping library for Robotics and SFM</a> -- Georgia Institute of Technology</li>
<li><a id="user-content-RainerKuemmerle/g2o" target="_blank" rel="noopener noreferrer" href="https://github.com/RainerKuemmerle/g2o">G2O: General framework for graph optomization</a><span class="ml-1 text-grey-dark whitespace-no-wrap"><span class="text-orange-dark">496 <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 14 13" width="14" height="12" class="mr-1"><polygon points="14 5 9.1 4.36 7 0 4.9 4.36 0 5 3.6 8.26 2.67 13 7 10.67 11.33 13 10.4 8.26"></polygon></svg></span><span class="text-green-dark">368 <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 14" width="10" height="12"><path d="M8,-8.47032947e-22 C7.09660216,-0.00238695453 6.3045861,0.603179379 6.07006224,1.47560813 C5.83553838,2.34803688 6.21717019,3.26909995 7,3.72 L7,5 L5,7 L3,5 L3,3.72 C3.78282981,3.26909995 4.16446162,2.34803688 3.92993776,1.47560813 C3.6954139,0.603179379 2.90339784,-0.00238695453 2,-4.44088363e-16 C1.09660216,-0.00238695453 0.304586097,0.603179379 0.0700622397,1.47560813 C-0.164461618,2.34803688 0.217170191,3.26909995 1,3.72 L1,5.5 L4,8.5 L4,10.28 C3.21717019,10.7309 2.83553838,11.6519631 3.07006224,12.5243919 C3.3045861,13.3968206 4.09660216,14.002387 5,14 C5.90339784,14.002387 6.6954139,13.3968206 6.92993776,12.5243919 C7.16446162,11.6519631 6.78282981,10.7309 6,10.28 L6,8.5 L9,5.5 L9,3.72 C9.78282981,3.26909995 10.1644616,2.34803688 9.92993776,1.47560813 C9.6954139,0.603179379 8.90339784,-0.00238695453 8,-8.47032947e-22 Z M2,3.2 C1.34,3.2 0.8,2.65 0.8,2 C0.8,1.35 1.35,0.8 2,0.8 C2.65,0.8 3.2,1.35 3.2,2 C3.2,2.65 2.65,3.2 2,3.2 Z M5,13.2 C4.34,13.2 3.8,12.65 3.8,12 C3.8,11.35 4.35,10.8 5,10.8 C5.65,10.8 6.2,11.35 6.2,12 C6.2,12.65 5.65,13.2 5,13.2 Z M8,3.2 C7.34,3.2 6.8,2.65 6.8,2 C6.8,1.35 7.35,0.8 8,0.8 C8.65,0.8 9.2,1.35 9.2,2 C9.2,2.65 8.65,3.2 8,3.2 Z"></path></svg></span></span></li>
</ul>
<h6><a href="#loop-closure" aria-hidden="true" class="anchor" id="user-content-loop-closure"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Loop Closure:</h6>
<ul>
<li><a target="_blank" rel="nofollow" href="http://www.robots.ox.ac.uk/%7Emjc/Software.htm">FabMap: appearance-based loop closure system</a> - also available in <a target="_blank" rel="nofollow" href="http://docs.opencv.org/2.4/modules/contrib/doc/openfabmap.html">OpenCV2.4.11</a></li>
<li><a target="_blank" rel="nofollow" href="http://webdiis.unizar.es/%7Edorian/index.php?p=32">DBoW2: binary bag-of-words loop detection system</a></li>
</ul>
<h6><a href="#localization--mapping" aria-hidden="true" class="anchor" id="user-content-localization--mapping"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Localization &amp; Mapping:</h6>
<ul>
<li><a target="_blank" rel="nofollow" href="https://code.google.com/p/ratslam/">RatSLAM</a></li>
<li><a id="user-content-tum-vision/lsd_slam" target="_blank" rel="noopener noreferrer" href="https://github.com/tum-vision/lsd_slam">LSD-SLAM</a><span class="ml-1 text-grey-dark whitespace-no-wrap"><span class="text-orange-dark">134 <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 14 13" width="14" height="12" class="mr-1"><polygon points="14 5 9.1 4.36 7 0 4.9 4.36 0 5 3.6 8.26 2.67 13 7 10.67 11.33 13 10.4 8.26"></polygon></svg></span><span class="text-green-dark">90 <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 14" width="10" height="12"><path d="M8,-8.47032947e-22 C7.09660216,-0.00238695453 6.3045861,0.603179379 6.07006224,1.47560813 C5.83553838,2.34803688 6.21717019,3.26909995 7,3.72 L7,5 L5,7 L3,5 L3,3.72 C3.78282981,3.26909995 4.16446162,2.34803688 3.92993776,1.47560813 C3.6954139,0.603179379 2.90339784,-0.00238695453 2,-4.44088363e-16 C1.09660216,-0.00238695453 0.304586097,0.603179379 0.0700622397,1.47560813 C-0.164461618,2.34803688 0.217170191,3.26909995 1,3.72 L1,5.5 L4,8.5 L4,10.28 C3.21717019,10.7309 2.83553838,11.6519631 3.07006224,12.5243919 C3.3045861,13.3968206 4.09660216,14.002387 5,14 C5.90339784,14.002387 6.6954139,13.3968206 6.92993776,12.5243919 C7.16446162,11.6519631 6.78282981,10.7309 6,10.28 L6,8.5 L9,5.5 L9,3.72 C9.78282981,3.26909995 10.1644616,2.34803688 9.92993776,1.47560813 C9.6954139,0.603179379 8.90339784,-0.00238695453 8,-8.47032947e-22 Z M2,3.2 C1.34,3.2 0.8,2.65 0.8,2 C0.8,1.35 1.35,0.8 2,0.8 C2.65,0.8 3.2,1.35 3.2,2 C3.2,2.65 2.65,3.2 2,3.2 Z M5,13.2 C4.34,13.2 3.8,12.65 3.8,12 C3.8,11.35 4.35,10.8 5,10.8 C5.65,10.8 6.2,11.35 6.2,12 C6.2,12.65 5.65,13.2 5,13.2 Z M8,3.2 C7.34,3.2 6.8,2.65 6.8,2 C6.8,1.35 7.35,0.8 8,0.8 C8.65,0.8 9.2,1.35 9.2,2 C9.2,2.65 8.65,3.2 8,3.2 Z"></path></svg></span></span></li>
<li><a id="user-content-raulmur/ORB_SLAM" target="_blank" rel="noopener noreferrer" href="https://github.com/raulmur/ORB_SLAM">ORB-SLAM</a><span class="ml-1 text-grey-dark whitespace-no-wrap"><span class="text-orange-dark">549 <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 14 13" width="14" height="12" class="mr-1"><polygon points="14 5 9.1 4.36 7 0 4.9 4.36 0 5 3.6 8.26 2.67 13 7 10.67 11.33 13 10.4 8.26"></polygon></svg></span><span class="text-green-dark">384 <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 14" width="10" height="12"><path d="M8,-8.47032947e-22 C7.09660216,-0.00238695453 6.3045861,0.603179379 6.07006224,1.47560813 C5.83553838,2.34803688 6.21717019,3.26909995 7,3.72 L7,5 L5,7 L3,5 L3,3.72 C3.78282981,3.26909995 4.16446162,2.34803688 3.92993776,1.47560813 C3.6954139,0.603179379 2.90339784,-0.00238695453 2,-4.44088363e-16 C1.09660216,-0.00238695453 0.304586097,0.603179379 0.0700622397,1.47560813 C-0.164461618,2.34803688 0.217170191,3.26909995 1,3.72 L1,5.5 L4,8.5 L4,10.28 C3.21717019,10.7309 2.83553838,11.6519631 3.07006224,12.5243919 C3.3045861,13.3968206 4.09660216,14.002387 5,14 C5.90339784,14.002387 6.6954139,13.3968206 6.92993776,12.5243919 C7.16446162,11.6519631 6.78282981,10.7309 6,10.28 L6,8.5 L9,5.5 L9,3.72 C9.78282981,3.26909995 10.1644616,2.34803688 9.92993776,1.47560813 C9.6954139,0.603179379 8.90339784,-0.00238695453 8,-8.47032947e-22 Z M2,3.2 C1.34,3.2 0.8,2.65 0.8,2 C0.8,1.35 1.35,0.8 2,0.8 C2.65,0.8 3.2,1.35 3.2,2 C3.2,2.65 2.65,3.2 2,3.2 Z M5,13.2 C4.34,13.2 3.8,12.65 3.8,12 C3.8,11.35 4.35,10.8 5,10.8 C5.65,10.8 6.2,11.35 6.2,12 C6.2,12.65 5.65,13.2 5,13.2 Z M8,3.2 C7.34,3.2 6.8,2.65 6.8,2 C6.8,1.35 7.35,0.8 8,0.8 C8.65,0.8 9.2,1.35 9.2,2 C9.2,2.65 8.65,3.2 8,3.2 Z"></path></svg></span></span></li>
</ul>
<h4><a href="#single-view-spatial-understanding" aria-hidden="true" class="anchor" id="user-content-single-view-spatial-understanding"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Single-view Spatial Understanding</h4>
<ul>
<li><a target="_blank" rel="nofollow" href="http://web.engr.illinois.edu/%7Edhoiem/projects/software.html">Geometric Context</a> - Derek Hoiem (CMU)</li>
<li><a target="_blank" rel="nofollow" href="http://web.engr.illinois.edu/%7Edhoiem/software/counter.php?Down=varsha_spatialLayout.zip">Recovering Spatial Layout</a> - Varsha Hedau (UIUC)</li>
<li><a target="_blank" rel="nofollow" href="http://www.cs.cmu.edu/%7E./dclee/code/index.html">Geometric Reasoning</a> - David C. Lee (CMU)</li>
<li><a id="user-content-arron2003/rgbd2full3d" target="_blank" rel="noopener noreferrer" href="https://github.com/arron2003/rgbd2full3d">RGBD2Full3D</a><span class="ml-1 text-grey-dark whitespace-no-wrap"><span class="text-grey-dark">4 <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 14 13" width="14" height="12" class="mr-1"><polygon points="14 5 9.1 4.36 7 0 4.9 4.36 0 5 3.6 8.26 2.67 13 7 10.67 11.33 13 10.4 8.26"></polygon></svg></span><span class="text-grey-dark">1 <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 14" width="10" height="12"><path d="M8,-8.47032947e-22 C7.09660216,-0.00238695453 6.3045861,0.603179379 6.07006224,1.47560813 C5.83553838,2.34803688 6.21717019,3.26909995 7,3.72 L7,5 L5,7 L3,5 L3,3.72 C3.78282981,3.26909995 4.16446162,2.34803688 3.92993776,1.47560813 C3.6954139,0.603179379 2.90339784,-0.00238695453 2,-4.44088363e-16 C1.09660216,-0.00238695453 0.304586097,0.603179379 0.0700622397,1.47560813 C-0.164461618,2.34803688 0.217170191,3.26909995 1,3.72 L1,5.5 L4,8.5 L4,10.28 C3.21717019,10.7309 2.83553838,11.6519631 3.07006224,12.5243919 C3.3045861,13.3968206 4.09660216,14.002387 5,14 C5.90339784,14.002387 6.6954139,13.3968206 6.92993776,12.5243919 C7.16446162,11.6519631 6.78282981,10.7309 6,10.28 L6,8.5 L9,5.5 L9,3.72 C9.78282981,3.26909995 10.1644616,2.34803688 9.92993776,1.47560813 C9.6954139,0.603179379 8.90339784,-0.00238695453 8,-8.47032947e-22 Z M2,3.2 C1.34,3.2 0.8,2.65 0.8,2 C0.8,1.35 1.35,0.8 2,0.8 C2.65,0.8 3.2,1.35 3.2,2 C3.2,2.65 2.65,3.2 2,3.2 Z M5,13.2 C4.34,13.2 3.8,12.65 3.8,12 C3.8,11.35 4.35,10.8 5,10.8 C5.65,10.8 6.2,11.35 6.2,12 C6.2,12.65 5.65,13.2 5,13.2 Z M8,3.2 C7.34,3.2 6.8,2.65 6.8,2 C6.8,1.35 7.35,0.8 8,0.8 C8.65,0.8 9.2,1.35 9.2,2 C9.2,2.65 8.65,3.2 8,3.2 Z"></path></svg></span></span> - Ruiqi Guo (UIUC)</li>
</ul>
<h4><a href="#object-detection" aria-hidden="true" class="anchor" id="user-content-object-detection"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Object Detection</h4>
<ul>
<li><a target="_blank" rel="nofollow" href="http://pascal.inrialpes.fr/soft/olt/">INRIA Object Detection and Localization Toolkit</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.cs.berkeley.edu/%7Erbg/latent/">Discriminatively trained deformable part models</a></li>
<li><a id="user-content-rbgirshick/voc-dpm" target="_blank" rel="noopener noreferrer" href="https://github.com/rbgirshick/voc-dpm">VOC-DPM</a><span class="ml-1 text-grey-dark whitespace-no-wrap"><span class="text-orange-dark">141 <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 14 13" width="14" height="12" class="mr-1"><polygon points="14 5 9.1 4.36 7 0 4.9 4.36 0 5 3.6 8.26 2.67 13 7 10.67 11.33 13 10.4 8.26"></polygon></svg></span><span class="text-green-dark">81 <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 14" width="10" height="12"><path d="M8,-8.47032947e-22 C7.09660216,-0.00238695453 6.3045861,0.603179379 6.07006224,1.47560813 C5.83553838,2.34803688 6.21717019,3.26909995 7,3.72 L7,5 L5,7 L3,5 L3,3.72 C3.78282981,3.26909995 4.16446162,2.34803688 3.92993776,1.47560813 C3.6954139,0.603179379 2.90339784,-0.00238695453 2,-4.44088363e-16 C1.09660216,-0.00238695453 0.304586097,0.603179379 0.0700622397,1.47560813 C-0.164461618,2.34803688 0.217170191,3.26909995 1,3.72 L1,5.5 L4,8.5 L4,10.28 C3.21717019,10.7309 2.83553838,11.6519631 3.07006224,12.5243919 C3.3045861,13.3968206 4.09660216,14.002387 5,14 C5.90339784,14.002387 6.6954139,13.3968206 6.92993776,12.5243919 C7.16446162,11.6519631 6.78282981,10.7309 6,10.28 L6,8.5 L9,5.5 L9,3.72 C9.78282981,3.26909995 10.1644616,2.34803688 9.92993776,1.47560813 C9.6954139,0.603179379 8.90339784,-0.00238695453 8,-8.47032947e-22 Z M2,3.2 C1.34,3.2 0.8,2.65 0.8,2 C0.8,1.35 1.35,0.8 2,0.8 C2.65,0.8 3.2,1.35 3.2,2 C3.2,2.65 2.65,3.2 2,3.2 Z M5,13.2 C4.34,13.2 3.8,12.65 3.8,12 C3.8,11.35 4.35,10.8 5,10.8 C5.65,10.8 6.2,11.35 6.2,12 C6.2,12.65 5.65,13.2 5,13.2 Z M8,3.2 C7.34,3.2 6.8,2.65 6.8,2 C6.8,1.35 7.35,0.8 8,0.8 C8.65,0.8 9.2,1.35 9.2,2 C9.2,2.65 8.65,3.2 8,3.2 Z"></path></svg></span></span></li>
<li><a target="_blank" rel="nofollow" href="http://www.ics.uci.edu/%7Edramanan/software/sparse/">Histograms of Sparse Codes for Object Detection</a></li>
<li><a id="user-content-rbgirshick/rcnn" target="_blank" rel="noopener noreferrer" href="https://github.com/rbgirshick/rcnn">R-CNN: Regions with Convolutional Neural Network Features</a><span class="ml-1 text-grey-dark whitespace-no-wrap"><span class="text-orange-dark">1k <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 14 13" width="14" height="12" class="mr-1"><polygon points="14 5 9.1 4.36 7 0 4.9 4.36 0 5 3.6 8.26 2.67 13 7 10.67 11.33 13 10.4 8.26"></polygon></svg></span><span class="text-green-dark">646 <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 14" width="10" height="12"><path d="M8,-8.47032947e-22 C7.09660216,-0.00238695453 6.3045861,0.603179379 6.07006224,1.47560813 C5.83553838,2.34803688 6.21717019,3.26909995 7,3.72 L7,5 L5,7 L3,5 L3,3.72 C3.78282981,3.26909995 4.16446162,2.34803688 3.92993776,1.47560813 C3.6954139,0.603179379 2.90339784,-0.00238695453 2,-4.44088363e-16 C1.09660216,-0.00238695453 0.304586097,0.603179379 0.0700622397,1.47560813 C-0.164461618,2.34803688 0.217170191,3.26909995 1,3.72 L1,5.5 L4,8.5 L4,10.28 C3.21717019,10.7309 2.83553838,11.6519631 3.07006224,12.5243919 C3.3045861,13.3968206 4.09660216,14.002387 5,14 C5.90339784,14.002387 6.6954139,13.3968206 6.92993776,12.5243919 C7.16446162,11.6519631 6.78282981,10.7309 6,10.28 L6,8.5 L9,5.5 L9,3.72 C9.78282981,3.26909995 10.1644616,2.34803688 9.92993776,1.47560813 C9.6954139,0.603179379 8.90339784,-0.00238695453 8,-8.47032947e-22 Z M2,3.2 C1.34,3.2 0.8,2.65 0.8,2 C0.8,1.35 1.35,0.8 2,0.8 C2.65,0.8 3.2,1.35 3.2,2 C3.2,2.65 2.65,3.2 2,3.2 Z M5,13.2 C4.34,13.2 3.8,12.65 3.8,12 C3.8,11.35 4.35,10.8 5,10.8 C5.65,10.8 6.2,11.35 6.2,12 C6.2,12.65 5.65,13.2 5,13.2 Z M8,3.2 C7.34,3.2 6.8,2.65 6.8,2 C6.8,1.35 7.35,0.8 8,0.8 C8.65,0.8 9.2,1.35 9.2,2 C9.2,2.65 8.65,3.2 8,3.2 Z"></path></svg></span></span></li>
<li><a id="user-content-ShaoqingRen/SPP_net" target="_blank" rel="noopener noreferrer" href="https://github.com/ShaoqingRen/SPP_net">SPP-Net</a><span class="ml-1 text-grey-dark whitespace-no-wrap"><span class="text-orange-dark">36 <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 14 13" width="14" height="12" class="mr-1"><polygon points="14 5 9.1 4.36 7 0 4.9 4.36 0 5 3.6 8.26 2.67 13 7 10.67 11.33 13 10.4 8.26"></polygon></svg></span><span class="text-grey-dark">25 <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 14" width="10" height="12"><path d="M8,-8.47032947e-22 C7.09660216,-0.00238695453 6.3045861,0.603179379 6.07006224,1.47560813 C5.83553838,2.34803688 6.21717019,3.26909995 7,3.72 L7,5 L5,7 L3,5 L3,3.72 C3.78282981,3.26909995 4.16446162,2.34803688 3.92993776,1.47560813 C3.6954139,0.603179379 2.90339784,-0.00238695453 2,-4.44088363e-16 C1.09660216,-0.00238695453 0.304586097,0.603179379 0.0700622397,1.47560813 C-0.164461618,2.34803688 0.217170191,3.26909995 1,3.72 L1,5.5 L4,8.5 L4,10.28 C3.21717019,10.7309 2.83553838,11.6519631 3.07006224,12.5243919 C3.3045861,13.3968206 4.09660216,14.002387 5,14 C5.90339784,14.002387 6.6954139,13.3968206 6.92993776,12.5243919 C7.16446162,11.6519631 6.78282981,10.7309 6,10.28 L6,8.5 L9,5.5 L9,3.72 C9.78282981,3.26909995 10.1644616,2.34803688 9.92993776,1.47560813 C9.6954139,0.603179379 8.90339784,-0.00238695453 8,-8.47032947e-22 Z M2,3.2 C1.34,3.2 0.8,2.65 0.8,2 C0.8,1.35 1.35,0.8 2,0.8 C2.65,0.8 3.2,1.35 3.2,2 C3.2,2.65 2.65,3.2 2,3.2 Z M5,13.2 C4.34,13.2 3.8,12.65 3.8,12 C3.8,11.35 4.35,10.8 5,10.8 C5.65,10.8 6.2,11.35 6.2,12 C6.2,12.65 5.65,13.2 5,13.2 Z M8,3.2 C7.34,3.2 6.8,2.65 6.8,2 C6.8,1.35 7.35,0.8 8,0.8 C8.65,0.8 9.2,1.35 9.2,2 C9.2,2.65 8.65,3.2 8,3.2 Z"></path></svg></span></span></li>
<li><a target="_blank" rel="nofollow" href="http://mmcheng.net/bing/comment-page-9/">BING: Objectness Estimation</a></li>
<li><a id="user-content-pdollar/edges" target="_blank" rel="noopener noreferrer" href="https://github.com/pdollar/edges">Edge Boxes</a><span class="ml-1 text-grey-dark whitespace-no-wrap"><span class="text-grey-dark">19 <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 14 13" width="14" height="12" class="mr-1"><polygon points="14 5 9.1 4.36 7 0 4.9 4.36 0 5 3.6 8.26 2.67 13 7 10.67 11.33 13 10.4 8.26"></polygon></svg></span><span class="text-grey-dark">10 <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 14" width="10" height="12"><path d="M8,-8.47032947e-22 C7.09660216,-0.00238695453 6.3045861,0.603179379 6.07006224,1.47560813 C5.83553838,2.34803688 6.21717019,3.26909995 7,3.72 L7,5 L5,7 L3,5 L3,3.72 C3.78282981,3.26909995 4.16446162,2.34803688 3.92993776,1.47560813 C3.6954139,0.603179379 2.90339784,-0.00238695453 2,-4.44088363e-16 C1.09660216,-0.00238695453 0.304586097,0.603179379 0.0700622397,1.47560813 C-0.164461618,2.34803688 0.217170191,3.26909995 1,3.72 L1,5.5 L4,8.5 L4,10.28 C3.21717019,10.7309 2.83553838,11.6519631 3.07006224,12.5243919 C3.3045861,13.3968206 4.09660216,14.002387 5,14 C5.90339784,14.002387 6.6954139,13.3968206 6.92993776,12.5243919 C7.16446162,11.6519631 6.78282981,10.7309 6,10.28 L6,8.5 L9,5.5 L9,3.72 C9.78282981,3.26909995 10.1644616,2.34803688 9.92993776,1.47560813 C9.6954139,0.603179379 8.90339784,-0.00238695453 8,-8.47032947e-22 Z M2,3.2 C1.34,3.2 0.8,2.65 0.8,2 C0.8,1.35 1.35,0.8 2,0.8 C2.65,0.8 3.2,1.35 3.2,2 C3.2,2.65 2.65,3.2 2,3.2 Z M5,13.2 C4.34,13.2 3.8,12.65 3.8,12 C3.8,11.35 4.35,10.8 5,10.8 C5.65,10.8 6.2,11.35 6.2,12 C6.2,12.65 5.65,13.2 5,13.2 Z M8,3.2 C7.34,3.2 6.8,2.65 6.8,2 C6.8,1.35 7.35,0.8 8,0.8 C8.65,0.8 9.2,1.35 9.2,2 C9.2,2.65 8.65,3.2 8,3.2 Z"></path></svg></span></span></li>
<li><a id="user-content-Russell91/ReInspect" target="_blank" rel="noopener noreferrer" href="https://github.com/Russell91/ReInspect">ReInspect</a><span class="ml-1 text-grey-dark whitespace-no-wrap"><span class="text-orange-dark">331 <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 14 13" width="14" height="12" class="mr-1"><polygon points="14 5 9.1 4.36 7 0 4.9 4.36 0 5 3.6 8.26 2.67 13 7 10.67 11.33 13 10.4 8.26"></polygon></svg></span><span class="text-green-dark">155 <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 14" width="10" height="12"><path d="M8,-8.47032947e-22 C7.09660216,-0.00238695453 6.3045861,0.603179379 6.07006224,1.47560813 C5.83553838,2.34803688 6.21717019,3.26909995 7,3.72 L7,5 L5,7 L3,5 L3,3.72 C3.78282981,3.26909995 4.16446162,2.34803688 3.92993776,1.47560813 C3.6954139,0.603179379 2.90339784,-0.00238695453 2,-4.44088363e-16 C1.09660216,-0.00238695453 0.304586097,0.603179379 0.0700622397,1.47560813 C-0.164461618,2.34803688 0.217170191,3.26909995 1,3.72 L1,5.5 L4,8.5 L4,10.28 C3.21717019,10.7309 2.83553838,11.6519631 3.07006224,12.5243919 C3.3045861,13.3968206 4.09660216,14.002387 5,14 C5.90339784,14.002387 6.6954139,13.3968206 6.92993776,12.5243919 C7.16446162,11.6519631 6.78282981,10.7309 6,10.28 L6,8.5 L9,5.5 L9,3.72 C9.78282981,3.26909995 10.1644616,2.34803688 9.92993776,1.47560813 C9.6954139,0.603179379 8.90339784,-0.00238695453 8,-8.47032947e-22 Z M2,3.2 C1.34,3.2 0.8,2.65 0.8,2 C0.8,1.35 1.35,0.8 2,0.8 C2.65,0.8 3.2,1.35 3.2,2 C3.2,2.65 2.65,3.2 2,3.2 Z M5,13.2 C4.34,13.2 3.8,12.65 3.8,12 C3.8,11.35 4.35,10.8 5,10.8 C5.65,10.8 6.2,11.35 6.2,12 C6.2,12.65 5.65,13.2 5,13.2 Z M8,3.2 C7.34,3.2 6.8,2.65 6.8,2 C6.8,1.35 7.35,0.8 8,0.8 C8.65,0.8 9.2,1.35 9.2,2 C9.2,2.65 8.65,3.2 8,3.2 Z"></path></svg></span></span></li>
</ul>
<h4><a href="#nearest-neighbor-search" aria-hidden="true" class="anchor" id="user-content-nearest-neighbor-search"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Nearest Neighbor Search</h4>
<h6><a href="#general-purpose-nearest-neighbor-search" aria-hidden="true" class="anchor" id="user-content-general-purpose-nearest-neighbor-search"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>General purpose nearest neighbor search</h6>
<ul>
<li><a target="_blank" rel="nofollow" href="http://www.cs.umd.edu/%7Emount/ANN/">ANN: A Library for Approximate Nearest Neighbor Searching</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.cs.ubc.ca/research/flann/">FLANN - Fast Library for Approximate Nearest Neighbors</a></li>
<li><a target="_blank" rel="nofollow" href="http://vincentfpgarcia.github.io/kNN-CUDA/">Fast k nearest neighbor search using GPU</a></li>
</ul>
<h6><a href="#nearest-neighbor-field-estimation" aria-hidden="true" class="anchor" id="user-content-nearest-neighbor-field-estimation"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Nearest Neighbor Field Estimation</h6>
<ul>
<li><a target="_blank" rel="nofollow" href="http://gfx.cs.princeton.edu/gfx/pubs/Barnes_2009_PAR/index.php">PatchMatch</a></li>
<li><a target="_blank" rel="nofollow" href="http://gfx.cs.princeton.edu/pubs/Barnes_2010_TGP/index.php">Generalized PatchMatch</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.eng.tau.ac.il/%7Esimonk/CSH/">Coherency Sensitive Hashing</a></li>
<li><a id="user-content-fbesse/pmbp" target="_blank" rel="noopener noreferrer" href="https://github.com/fbesse/pmbp">PMBP: PatchMatch Belief Propagation</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.eng.tau.ac.il/%7Eavidan/papers/TreeCANN_code_20121022.rar">TreeCANN</a></li>
</ul>
<h4><a href="#visual-tracking" aria-hidden="true" class="anchor" id="user-content-visual-tracking"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Visual Tracking</h4>
<ul>
<li><a target="_blank" rel="nofollow" href="https://sites.google.com/site/trackerbenchmark/benchmarks/v10">Visual Tracker Benchmark</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.votchallenge.net/">Visual Tracking Challenge</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.ces.clemson.edu/%7Estb/klt/">Kanade-Lucas-Tomasi Feature Tracker</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.eng.tau.ac.il/%7Eoron/ELK/ELK.html">Extended Lucas-Kanade Tracking</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.vision.ee.ethz.ch/boostingTrackers/">Online-boosting Tracking</a></li>
<li><a target="_blank" rel="nofollow" href="http://www4.comp.polyu.edu.hk/%7Ecslzhang/STC/STC.htm">Spatio-Temporal Context Learning</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.shengfenghe.com/visual-tracking-via-locality-sensitive-histograms.html">Locality Sensitive Histograms</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.cv-foundation.org/openaccess/content_iccv_workshops_2013/W03/papers/Xiao_An_Enhanced_Adaptive_2013_ICCV_paper.pdf">Enhanced adaptive coupled-layer LGTracker++</a></li>
<li><a target="_blank" rel="nofollow" href="http://personal.ee.surrey.ac.uk/Personal/Z.Kalal/tld.html">TLD: Tracking - Learning - Detection</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.gnebehay.com/cmt/">CMT: Clustering of Static-Adaptive Correspondences for Deformable Object Tracking</a></li>
<li><a target="_blank" rel="nofollow" href="http://home.isr.uc.pt/%7Ehenriques/circulant/">Kernelized Correlation Filters</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.cvl.isy.liu.se/en/research/objrec/visualtracking/scalvistrack/index.html">Accurate Scale Estimation for Robust Visual Tracking</a></li>
<li><a target="_blank" rel="nofollow" href="http://cs-people.bu.edu/jmzhang/MEEM/MEEM.html">Multiple Experts using Entropy Minimization</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.dabi.temple.edu/%7Ehbling/code/TGPR.htm">TGPR</a></li>
<li><a target="_blank" rel="nofollow" href="https://sites.google.com/site/jbhuang0604/publications/cf2">CF2: Hierarchical Convolutional Features for Visual Tracking</a></li>
<li><a target="_blank" rel="nofollow" href="http://webdocs.cs.ualberta.ca/%7Evis/mtf/index.html">Modular Tracking Framework</a></li>
</ul>
<h4><a href="#saliency-detection" aria-hidden="true" class="anchor" id="user-content-saliency-detection"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Saliency Detection</h4>
<h4><a href="#attributes" aria-hidden="true" class="anchor" id="user-content-attributes"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Attributes</h4>
<h4><a href="#action-reconition" aria-hidden="true" class="anchor" id="user-content-action-reconition"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Action Reconition</h4>
<h4><a href="#egocentric-cameras" aria-hidden="true" class="anchor" id="user-content-egocentric-cameras"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Egocentric cameras</h4>
<h4><a href="#human-in-the-loop-systems" aria-hidden="true" class="anchor" id="user-content-human-in-the-loop-systems"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Human-in-the-loop systems</h4>
<h4><a href="#image-captioning" aria-hidden="true" class="anchor" id="user-content-image-captioning"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Image Captioning</h4>
<ul>
<li><a id="user-content-karpathy/neuraltalk%EF%BB%BF" target="_blank" rel="noopener noreferrer" href="https://github.com/karpathy/neuraltalk%EF%BB%BF">NeuralTalk</a> -</li>
</ul>
<h4><a href="#optimization-2" aria-hidden="true" class="anchor" id="user-content-optimization-2"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Optimization</h4>
<ul>
<li><a target="_blank" rel="nofollow" href="http://ceres-solver.org/">Ceres Solver</a> - Nonlinear least-square problem and unconstrained optimization solver</li>
<li><a target="_blank" rel="nofollow" href="http://ab-initio.mit.edu/wiki/index.php/NLopt">NLopt</a>- Nonlinear least-square problem and unconstrained optimization solver</li>
<li><a target="_blank" rel="nofollow" href="http://hci.iwr.uni-heidelberg.de/opengm2/">OpenGM</a> - Factor graph based discrete optimization and inference solver</li>
<li><a target="_blank" rel="nofollow" href="https://collab.cc.gatech.edu/borg/gtsam/">GTSAM</a> - Factor graph based lease-square optimization solver</li>
</ul>
<h4><a href="#deep-learning-1" aria-hidden="true" class="anchor" id="user-content-deep-learning-1"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Deep Learning</h4>
<ul>
<li><a id="user-content-kjw0612/awesome-deep-vision" target="_blank" rel="noopener noreferrer" href="https://github.com/kjw0612/awesome-deep-vision">Awesome Deep Vision</a><span class="ml-1 text-grey-dark whitespace-no-wrap"><span class="text-orange-dark">4k <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 14 13" width="14" height="12" class="mr-1"><polygon points="14 5 9.1 4.36 7 0 4.9 4.36 0 5 3.6 8.26 2.67 13 7 10.67 11.33 13 10.4 8.26"></polygon></svg></span><span class="text-green-dark">1k <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 14" width="10" height="12"><path d="M8,-8.47032947e-22 C7.09660216,-0.00238695453 6.3045861,0.603179379 6.07006224,1.47560813 C5.83553838,2.34803688 6.21717019,3.26909995 7,3.72 L7,5 L5,7 L3,5 L3,3.72 C3.78282981,3.26909995 4.16446162,2.34803688 3.92993776,1.47560813 C3.6954139,0.603179379 2.90339784,-0.00238695453 2,-4.44088363e-16 C1.09660216,-0.00238695453 0.304586097,0.603179379 0.0700622397,1.47560813 C-0.164461618,2.34803688 0.217170191,3.26909995 1,3.72 L1,5.5 L4,8.5 L4,10.28 C3.21717019,10.7309 2.83553838,11.6519631 3.07006224,12.5243919 C3.3045861,13.3968206 4.09660216,14.002387 5,14 C5.90339784,14.002387 6.6954139,13.3968206 6.92993776,12.5243919 C7.16446162,11.6519631 6.78282981,10.7309 6,10.28 L6,8.5 L9,5.5 L9,3.72 C9.78282981,3.26909995 10.1644616,2.34803688 9.92993776,1.47560813 C9.6954139,0.603179379 8.90339784,-0.00238695453 8,-8.47032947e-22 Z M2,3.2 C1.34,3.2 0.8,2.65 0.8,2 C0.8,1.35 1.35,0.8 2,0.8 C2.65,0.8 3.2,1.35 3.2,2 C3.2,2.65 2.65,3.2 2,3.2 Z M5,13.2 C4.34,13.2 3.8,12.65 3.8,12 C3.8,11.35 4.35,10.8 5,10.8 C5.65,10.8 6.2,11.35 6.2,12 C6.2,12.65 5.65,13.2 5,13.2 Z M8,3.2 C7.34,3.2 6.8,2.65 6.8,2 C6.8,1.35 7.35,0.8 8,0.8 C8.65,0.8 9.2,1.35 9.2,2 C9.2,2.65 8.65,3.2 8,3.2 Z"></path></svg></span></span></li>
</ul>
<h4><a href="#machine-learning-2" aria-hidden="true" class="anchor" id="user-content-machine-learning-2"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Machine Learning</h4>
<ul>
<li><a id="user-content-josephmisiti/awesome-machine-learning" target="_blank" rel="noopener noreferrer" href="https://github.com/josephmisiti/awesome-machine-learning">Awesome Machine Learning</a><span class="ml-1 text-grey-dark whitespace-no-wrap"><span class="text-orange-dark">4k <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 14 13" width="14" height="12" class="mr-1"><polygon points="14 5 9.1 4.36 7 0 4.9 4.36 0 5 3.6 8.26 2.67 13 7 10.67 11.33 13 10.4 8.26"></polygon></svg></span><span class="text-green-dark">678 <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 14" width="10" height="12"><path d="M8,-8.47032947e-22 C7.09660216,-0.00238695453 6.3045861,0.603179379 6.07006224,1.47560813 C5.83553838,2.34803688 6.21717019,3.26909995 7,3.72 L7,5 L5,7 L3,5 L3,3.72 C3.78282981,3.26909995 4.16446162,2.34803688 3.92993776,1.47560813 C3.6954139,0.603179379 2.90339784,-0.00238695453 2,-4.44088363e-16 C1.09660216,-0.00238695453 0.304586097,0.603179379 0.0700622397,1.47560813 C-0.164461618,2.34803688 0.217170191,3.26909995 1,3.72 L1,5.5 L4,8.5 L4,10.28 C3.21717019,10.7309 2.83553838,11.6519631 3.07006224,12.5243919 C3.3045861,13.3968206 4.09660216,14.002387 5,14 C5.90339784,14.002387 6.6954139,13.3968206 6.92993776,12.5243919 C7.16446162,11.6519631 6.78282981,10.7309 6,10.28 L6,8.5 L9,5.5 L9,3.72 C9.78282981,3.26909995 10.1644616,2.34803688 9.92993776,1.47560813 C9.6954139,0.603179379 8.90339784,-0.00238695453 8,-8.47032947e-22 Z M2,3.2 C1.34,3.2 0.8,2.65 0.8,2 C0.8,1.35 1.35,0.8 2,0.8 C2.65,0.8 3.2,1.35 3.2,2 C3.2,2.65 2.65,3.2 2,3.2 Z M5,13.2 C4.34,13.2 3.8,12.65 3.8,12 C3.8,11.35 4.35,10.8 5,10.8 C5.65,10.8 6.2,11.35 6.2,12 C6.2,12.65 5.65,13.2 5,13.2 Z M8,3.2 C7.34,3.2 6.8,2.65 6.8,2 C6.8,1.35 7.35,0.8 8,0.8 C8.65,0.8 9.2,1.35 9.2,2 C9.2,2.65 8.65,3.2 8,3.2 Z"></path></svg></span></span></li>
<li><a target="_blank" rel="nofollow" href="http://idiap.github.io/bob/">Bob: a free signal processing and machine learning toolbox for researchers</a></li>
<li><a target="_blank" rel="nofollow" href="https://www.csie.ntu.edu.tw/%7Ecjlin/libsvm/">LIBSVM -- A Library for Support Vector Machines</a></li>
</ul>
<h2><a href="#datasets" aria-hidden="true" class="anchor" id="user-content-datasets"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Datasets</h2>
<h4><a href="#external-dataset-link-collection" aria-hidden="true" class="anchor" id="user-content-external-dataset-link-collection"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>External Dataset Link Collection</h4>
<ul>
<li><a target="_blank" rel="nofollow" href="http://www.cvpapers.com/datasets.html">CV Datasets on the web</a> - CVPapers</li>
<li><a target="_blank" rel="nofollow" href="http://rodrigob.github.io/are_we_there_yet/build/">Are we there yet?</a> - Which paper provides the best results on standard dataset X?</li>
<li><a target="_blank" rel="nofollow" href="http://www.cvpapers.com/datasets.html">Computer Vision Dataset on the web</a></li>
<li><a target="_blank" rel="nofollow" href="http://riemenschneider.hayko.at/vision/dataset/">Yet Another Computer Vision Index To Datasets</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.computervisiononline.com/datasets">ComputerVisionOnline Datasets</a></li>
<li><a target="_blank" rel="nofollow" href="http://homepages.inf.ed.ac.uk/cgi/rbf/CVONLINE/entries.pl?TAG363">CVOnline Dataset</a></li>
<li><a target="_blank" rel="nofollow" href="http://clickdamage.com/sourcecode/cv_datasets.php">CV datasets</a></li>
<li><a target="_blank" rel="nofollow" href="http://datasets.visionbib.com/info-index.html">visionbib</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.visualdata.io/">VisualData</a></li>
</ul>
<h4><a href="#low-level-vision-1" aria-hidden="true" class="anchor" id="user-content-low-level-vision-1"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Low-level Vision</h4>
<h6><a href="#stereo-vision-1" aria-hidden="true" class="anchor" id="user-content-stereo-vision-1"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Stereo Vision</h6>
<ul>
<li><a target="_blank" rel="nofollow" href="http://vision.middlebury.edu/stereo/">Middlebury Stereo Vision</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.cvlibs.net/datasets/kitti/eval_stereo_flow.php?benchmark=stero">The KITTI Vision Benchmark Suite</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.cvlibs.net/software/libelas/">LIBELAS: Library for Efficient Large-scale Stereo Matching</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.6d-vision.com/ground-truth-stixel-dataset">Ground Truth Stixel Dataset</a></li>
</ul>
<h6><a href="#optical-flow-1" aria-hidden="true" class="anchor" id="user-content-optical-flow-1"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Optical Flow</h6>
<ul>
<li><a target="_blank" rel="nofollow" href="http://vision.middlebury.edu/flow/">Middlebury Optical Flow Evaluation</a></li>
<li><a target="_blank" rel="nofollow" href="http://sintel.is.tue.mpg.de/">MPI-Sintel Optical Flow Dataset and Evaluation</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.cvlibs.net/datasets/kitti/eval_stereo_flow.php?benchmark=flow">The KITTI Vision Benchmark Suite</a></li>
<li><a target="_blank" rel="nofollow" href="http://hci.iwr.uni-heidelberg.de/Benchmarks/document/Challenging_Data_for_Stereo_and_Optical_Flow/">HCI Challenge</a></li>
</ul>
<h6><a href="#video-object-segmentation" aria-hidden="true" class="anchor" id="user-content-video-object-segmentation"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Video Object Segmentation</h6>
<ul>
<li><a target="_blank" rel="nofollow" href="http://davischallenge.org/">DAVIS: Densely Annotated VIdeo Segmentation</a></li>
<li><a target="_blank" rel="nofollow" href="http://web.engr.oregonstate.edu/%7Elif/SegTrack2/dataset.html">SegTrack v2</a></li>
</ul>
<h6><a href="#change-detection" aria-hidden="true" class="anchor" id="user-content-change-detection"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Change Detection</h6>
<ul>
<li><a target="_blank" rel="nofollow" href="http://www.gti.ssr.upm.es/data/LASIESTA">Labeled and Annotated Sequences for Integral Evaluation of SegmenTation Algorithms</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.changedetection.net/">ChangeDetection.net</a></li>
</ul>
<h6><a href="#image-super-resolutions" aria-hidden="true" class="anchor" id="user-content-image-super-resolutions"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Image Super-resolutions</h6>
<ul>
<li><a target="_blank" rel="nofollow" href="https://eng.ucmerced.edu/people/cyang35/ECCV14/ECCV14.html">Single-Image Super-Resolution: A Benchmark</a></li>
</ul>
<h4><a href="#intrinsic-images-1" aria-hidden="true" class="anchor" id="user-content-intrinsic-images-1"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Intrinsic Images</h4>
<ul>
<li><a target="_blank" rel="nofollow" href="http://www.mit.edu/%7Ekimo/publications/intrinsic/">Ground-truth dataset and baseline evaluations for intrinsic image algorithms</a></li>
<li><a target="_blank" rel="nofollow" href="http://opensurfaces.cs.cornell.edu/intrinsic/">Intrinsic Images in the Wild</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.cic.uab.cat/Datasets/synthetic_intrinsic_image_dataset/">Intrinsic Image Evaluation on Synthetic Complex Scenes</a></li>
</ul>
<h4><a href="#material-recognition" aria-hidden="true" class="anchor" id="user-content-material-recognition"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Material Recognition</h4>
<ul>
<li><a target="_blank" rel="nofollow" href="http://opensurfaces.cs.cornell.edu/">OpenSurface</a></li>
<li><a target="_blank" rel="nofollow" href="http://people.csail.mit.edu/celiu/CVPR2010/">Flickr Material Database</a></li>
<li><a target="_blank" rel="nofollow" href="http://opensurfaces.cs.cornell.edu/publications/minc/">Materials in Context Dataset</a></li>
</ul>
<h4><a href="#multi-view-reconsturction" aria-hidden="true" class="anchor" id="user-content-multi-view-reconsturction"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Multi-view Reconsturction</h4>
<ul>
<li><a target="_blank" rel="nofollow" href="http://vision.middlebury.edu/mview/">Multi-View Stereo Reconstruction</a></li>
</ul>
<h4><a href="#saliency-detection-1" aria-hidden="true" class="anchor" id="user-content-saliency-detection-1"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Saliency Detection</h4>
<h4><a href="#visual-tracking-1" aria-hidden="true" class="anchor" id="user-content-visual-tracking-1"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Visual Tracking</h4>
<ul>
<li><a target="_blank" rel="nofollow" href="https://sites.google.com/site/trackerbenchmark/benchmarks/v10">Visual Tracker Benchmark</a></li>
<li><a target="_blank" rel="nofollow" href="https://sites.google.com/site/benchmarkpami/">Visual Tracker Benchmark v1.1</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.votchallenge.net/">VOT Challenge</a></li>
<li><a target="_blank" rel="nofollow" href="http://tracking.cs.princeton.edu/">Princeton Tracking Benchmark</a></li>
<li><a target="_blank" rel="nofollow" href="http://webdocs.cs.ualberta.ca/%7Evis/trackDB/">Tracking Manipulation Tasks (TMT)</a></li>
</ul>
<h4><a href="#visual-surveillance" aria-hidden="true" class="anchor" id="user-content-visual-surveillance"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Visual Surveillance</h4>
<ul>
<li><a target="_blank" rel="nofollow" href="http://www.viratdata.org/">VIRAT</a></li>
<li><a target="_blank" rel="nofollow" href="https://cam2.ecn.purdue.edu/">CAM2</a></li>
</ul>
<h4><a href="#saliency-detection-2" aria-hidden="true" class="anchor" id="user-content-saliency-detection-2"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Saliency Detection</h4>
<h4><a href="#change-detection-1" aria-hidden="true" class="anchor" id="user-content-change-detection-1"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Change detection</h4>
<ul>
<li><a target="_blank" rel="nofollow" href="http://changedetection.net/">ChangeDetection.net</a></li>
</ul>
<h4><a href="#visual-recognition" aria-hidden="true" class="anchor" id="user-content-visual-recognition"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Visual Recognition</h4>
<h6><a href="#image-classification" aria-hidden="true" class="anchor" id="user-content-image-classification"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Image Classification</h6>
<ul>
<li><a target="_blank" rel="nofollow" href="http://pascallin.ecs.soton.ac.uk/challenges/VOC/">The PASCAL Visual Object Classes</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.image-net.org/challenges/LSVRC/2014/">ImageNet Large Scale Visual Recognition Challenge</a></li>
</ul>
<h6><a href="#scene-recognition" aria-hidden="true" class="anchor" id="user-content-scene-recognition"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Scene Recognition</h6>
<ul>
<li><a target="_blank" rel="nofollow" href="http://groups.csail.mit.edu/vision/SUN/">SUN Database</a></li>
<li><a target="_blank" rel="nofollow" href="http://places.csail.mit.edu/">Place Dataset</a></li>
</ul>
<h6><a href="#object-detection-1" aria-hidden="true" class="anchor" id="user-content-object-detection-1"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Object Detection</h6>
<ul>
<li><a target="_blank" rel="nofollow" href="http://pascallin.ecs.soton.ac.uk/challenges/VOC/">The PASCAL Visual Object Classes</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.image-net.org/challenges/LSVRC/2014/">ImageNet Object Detection Challenge</a></li>
<li><a target="_blank" rel="nofollow" href="http://mscoco.org/">Microsoft COCO</a></li>
</ul>
<h6><a href="#semantic-labeling" aria-hidden="true" class="anchor" id="user-content-semantic-labeling"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Semantic labeling</h6>
<ul>
<li><a target="_blank" rel="nofollow" href="http://dags.stanford.edu/projects/scenedataset.html">Stanford background dataset</a></li>
<li><a target="_blank" rel="nofollow" href="http://mi.eng.cam.ac.uk/research/projects/VideoRec/CamVid/">CamVid</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.cs.unc.edu/%7Ejtighe/Papers/ECCV10/">Barcelona Dataset</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.cs.unc.edu/%7Ejtighe/Papers/ECCV10/siftflow/SiftFlowDataset.zip">SIFT Flow Dataset</a></li>
</ul>
<h6><a href="#multi-view-object-detection" aria-hidden="true" class="anchor" id="user-content-multi-view-object-detection"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Multi-view Object Detection</h6>
<ul>
<li><a target="_blank" rel="nofollow" href="http://cvgl.stanford.edu/resources.html">3D Object Dataset</a></li>
<li><a target="_blank" rel="nofollow" href="http://cvlab.epfl.ch/data/pose">EPFL Car Dataset</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.cvlibs.net/datasets/kitti/eval_object.php">KTTI Dection Dataset</a></li>
<li><a target="_blank" rel="nofollow" href="http://sun3d.cs.princeton.edu/">SUN 3D Dataset</a></li>
<li><a target="_blank" rel="nofollow" href="http://cvgl.stanford.edu/projects/pascal3d.html">PASCAL 3D+</a></li>
<li><a target="_blank" rel="nofollow" href="http://nyc3d.cs.cornell.edu/">NYU Car Dataset</a></li>
</ul>
<h6><a href="#fine-grained-visual-recognition" aria-hidden="true" class="anchor" id="user-content-fine-grained-visual-recognition"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Fine-grained Visual Recognition</h6>
<ul>
<li><a target="_blank" rel="nofollow" href="https://sites.google.com/site/fgcomp2013/">Fine-grained Classification Challenge</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.vision.caltech.edu/visipedia/CUB-200.html">Caltech-UCSD Birds 200</a></li>
</ul>
<h6><a href="#pedestrian-detection" aria-hidden="true" class="anchor" id="user-content-pedestrian-detection"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Pedestrian Detection</h6>
<ul>
<li><a target="_blank" rel="nofollow" href="http://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/">Caltech Pedestrian Detection Benchmark</a></li>
<li><a target="_blank" rel="nofollow" href="https://data.vision.ee.ethz.ch/cvl/aess/dataset/">ETHZ Pedestrian Detection</a></li>
</ul>
<h4><a href="#action-recognition" aria-hidden="true" class="anchor" id="user-content-action-recognition"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Action Recognition</h4>
<h6><a href="#image-based" aria-hidden="true" class="anchor" id="user-content-image-based"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Image-based</h6>
<h6><a href="#video-based" aria-hidden="true" class="anchor" id="user-content-video-based"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Video-based</h6>
<ul>
<li><a target="_blank" rel="nofollow" href="http://www.di.ens.fr/%7Elaptev/actions/hollywood2/">HOLLYWOOD2 Dataset</a></li>
<li><a target="_blank" rel="nofollow" href="http://crcv.ucf.edu/data/UCF_Sports_Action.php">UCF Sports Action Data Set</a></li>
</ul>
<h6><a href="#image-deblurring-1" aria-hidden="true" class="anchor" id="user-content-image-deblurring-1"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Image Deblurring</h6>
<ul>
<li><a target="_blank" rel="nofollow" href="http://cs.brown.edu/%7Elbsun/deblur2013/deblur2013iccp.html">Sun dataset</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.wisdom.weizmann.ac.il/%7Elevina/papers/LevinEtalCVPR09Data.rar">Levin dataset</a></li>
</ul>
<h4><a href="#image-captioning-1" aria-hidden="true" class="anchor" id="user-content-image-captioning-1"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Image Captioning</h4>
<ul>
<li><a target="_blank" rel="nofollow" href="http://nlp.cs.illinois.edu/HockenmaierGroup/Framing_Image_Description/KCCA.html">Flickr 8K</a></li>
<li><a target="_blank" rel="nofollow" href="http://shannon.cs.illinois.edu/DenotationGraph/">Flickr 30K</a></li>
<li><a target="_blank" rel="nofollow" href="http://mscoco.org/">Microsoft COCO</a></li>
</ul>
<h4><a href="#scene-understanding" aria-hidden="true" class="anchor" id="user-content-scene-understanding"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Scene Understanding</h4>
<h1><a href="#sun-rgb-d---a-rgb-d-scene-understanding-benchmark-suite" aria-hidden="true" class="anchor" id="user-content-sun-rgb-d---a-rgb-d-scene-understanding-benchmark-suite"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><a target="_blank" rel="nofollow" href="http://rgbd.cs.princeton.edu/">SUN RGB-D</a> - A RGB-D Scene Understanding Benchmark Suite</h1>
<h1><a href="#nyu-depth-v2---indoor-segmentation-and-support-inference-from-rgbd-images" aria-hidden="true" class="anchor" id="user-content-nyu-depth-v2---indoor-segmentation-and-support-inference-from-rgbd-images"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><a target="_blank" rel="nofollow" href="http://cs.nyu.edu/%7Esilberman/datasets/nyu_depth_v2.html">NYU depth v2</a> - Indoor Segmentation and Support Inference from RGBD Images</h1>
<h4><a href="#aerial-images" aria-hidden="true" class="anchor" id="user-content-aerial-images"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Aerial images</h4>
<h1><a href="#aerial-image-segmentation---learning-aerial-image-segmentation-from-online-maps" aria-hidden="true" class="anchor" id="user-content-aerial-image-segmentation---learning-aerial-image-segmentation-from-online-maps"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><a target="_blank" rel="nofollow" href="https://zenodo.org/record/1154821#.WmN9kHWnHIp">Aerial Image Segmentation</a> - Learning Aerial Image Segmentation From Online Maps</h1>
<h2><a href="#resources-for-students" aria-hidden="true" class="anchor" id="user-content-resources-for-students"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Resources for students</h2>
<h4><a href="#resource-link-collection" aria-hidden="true" class="anchor" id="user-content-resource-link-collection"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Resource link collection</h4>
<ul>
<li><a target="_blank" rel="nofollow" href="http://people.csail.mit.edu/fredo/student.html">Resources for students</a> - Frédo Durand (MIT)</li>
<li><a target="_blank" rel="nofollow" href="http://www.dgp.toronto.edu/%7Ehertzman/advice/">Advice for Graduate Students</a> - Aaron Hertzmann (Adobe Research)</li>
<li><a target="_blank" rel="nofollow" href="http://www.dgp.toronto.edu/%7Ehertzman/courses/gradSkills/2010/">Graduate Skills Seminars</a> - Yashar Ganjali, Aaron Hertzmann (University of Toronto)</li>
<li><a target="_blank" rel="nofollow" href="http://research.microsoft.com/en-us/um/people/simonpj/papers/giving-a-talk/giving-a-talk.htm">Research Skills</a> - Simon Peyton Jones (Microsoft Research)</li>
<li><a target="_blank" rel="nofollow" href="http://web.engr.illinois.edu/%7Etaoxie/advice.htm">Resource collection</a> - Tao Xie (UIUC) and Yuan Xie (UCSB)</li>
</ul>
<h4><a href="#writing" aria-hidden="true" class="anchor" id="user-content-writing"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Writing</h4>
<ul>
<li><a target="_blank" rel="nofollow" href="http://people.csail.mit.edu/fredo/FredoGoodWriting.pdf">Write Good Papers</a> - Frédo Durand (MIT)</li>
<li><a target="_blank" rel="nofollow" href="http://people.csail.mit.edu/fredo/PUBLI/writing.pdf">Notes on writing</a> - Frédo Durand (MIT)</li>
<li><a target="_blank" rel="nofollow" href="http://people.csail.mit.edu/fredo/FredoBadWriting.pdf">How to Write a Bad Article</a> - Frédo Durand (MIT)</li>
<li><a target="_blank" rel="nofollow" href="http://billf.mit.edu/sites/default/files/documents/cvprPapers.pdf">How to write a good CVPR submission</a> - William T. Freeman (MIT)</li>
<li><a target="_blank" rel="nofollow" href="https://www.youtube.com/watch?v=g3dkRsTqdDA">How to write a great research paper</a> - Simon Peyton Jones (Microsoft Research)</li>
<li><a target="_blank" rel="nofollow" href="http://www.slideshare.net/jdily/how-to-write-a-siggraph-paper">How to write a SIGGRAPH paper</a> - SIGGRAPH ASIA 2011 Course</li>
<li><a target="_blank" rel="nofollow" href="http://www.dgp.toronto.edu/%7Ehertzman/advice/writing-technical-papers.pdf">Writing Research Papers</a> - Aaron Hertzmann (Adobe Research)</li>
<li><a target="_blank" rel="nofollow" href="http://www.computer.org/csdl/mags/cg/1987/12/mcg1987120062.pdf">How to Write a Paper for SIGGRAPH</a> - Jim Blinn</li>
<li><a target="_blank" rel="nofollow" href="http://www.siggraph.org/sites/default/files/kajiya.pdf">How to Get Your SIGGRAPH Paper Rejected</a> - Jim Kajiya (Microsoft Research)</li>
<li><a target="_blank" rel="noopener noreferrer" href="https://github.com/jbhuang0604/awesome-computer-vision/blob/master/www.liyiwei.org/courses/how-siga11/liyiwei.pptx">How to write a SIGGRAPH paper</a> - Li-Yi Wei (The University of Hong Kong)</li>
<li><a target="_blank" rel="nofollow" href="http://www-hagen.informatik.uni-kl.de/%7Ebertram/talks/getpublished.pdf">How to Write a Great Paper</a> - Martin Martin Hering Hering--Bertram (Hochschule Bremen University of Applied Sciences)</li>
<li><a target="_blank" rel="nofollow" href="http://www-ui.is.s.u-tokyo.ac.jp/%7Etakeo/writings/siggraph.html">How to have a paper get into SIGGRAPH?</a> - Takeo Igarashi (The University of Tokyo)</li>
<li><a target="_blank" rel="nofollow" href="http://www.cs.cmu.edu/%7Epausch/Randy/Randy/raibert.htm">Good Writing</a> - Marc H. Raibert (Boston Dynamics, Inc.)</li>
<li><a target="_blank" rel="nofollow" href="http://web.engr.illinois.edu/%7Edhoiem/presentations/How%20to%20Write%20a%20Computer%20Vison%20Paper.ppt">How to Write a Computer Vision Paper</a> - Derek Hoiem (UIUC)</li>
<li><a target="_blank" rel="nofollow" href="http://www.cs.dartmouth.edu/%7Ewjarosz/writing.html">Common mistakes in technical writing</a> - Wojciech Jarosz (Dartmouth College)</li>
</ul>
<h4><a href="#presentation" aria-hidden="true" class="anchor" id="user-content-presentation"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Presentation</h4>
<ul>
<li><a target="_blank" rel="nofollow" href="http://people.csail.mit.edu/fredo/TalkAdvice.pdf">Giving a Research Talk</a> - Frédo Durand (MIT)</li>
<li><a target="_blank" rel="nofollow" href="http://www.dgp.toronto.edu/%7Ehertzman/courses/gradSkills/2010/GivingGoodTalks.pdf">How to give a good talk</a> - David Fleet (University of Toronto) and Aaron Hertzmann (Adobe Research)</li>
<li><a target="_blank" rel="nofollow" href="http://colinpurrington.com/tips/poster-design">Designing conference posters</a> - Colin Purrington</li>
</ul>
<h4><a href="#research" aria-hidden="true" class="anchor" id="user-content-research"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Research</h4>
<ul>
<li><a target="_blank" rel="nofollow" href="http://people.csail.mit.edu/billf/www/papers/doresearch.pdf">How to do research</a> - William T. Freeman (MIT)</li>
<li><a target="_blank" rel="nofollow" href="http://www.cs.virginia.edu/%7Erobins/YouAndYourResearch.html">You and Your Research</a> - Richard Hamming</li>
<li><a target="_blank" rel="nofollow" href="http://yima.csl.illinois.edu/psfile/bogus.pdf">Warning Signs of Bogus Progress in Research in an Age of Rich Computation and Information</a> - Yi Ma (UIUC)</li>
<li><a target="_blank" rel="nofollow" href="http://www.quackwatch.com/01QuackeryRelatedTopics/signs.html">Seven Warning Signs of Bogus Science</a> - Robert L. Park</li>
<li><a target="_blank" rel="nofollow" href="https://www.youtube.com/watch?v=v2Qaf8t8I6c">Five Principles for Choosing Research Problems in Computer Graphics</a> - Thomas Funkhouser (Cornell University)</li>
<li><a target="_blank" rel="nofollow" href="http://www.cs.indiana.edu/mit.research.how.to.html">How To Do Research In the MIT AI Lab</a> - David Chapman (MIT)</li>
<li><a target="_blank" rel="nofollow" href="http://www.slideshare.net/antiw/recent-advances-in-computer-vision">Recent Advances in Computer Vision</a> - Ming-Hsuan Yang (UC Merced)</li>
<li><a target="_blank" rel="nofollow" href="http://www.slideshare.net/jbhuang/how-to-come-up-with-new-research-ideas-4005840">How to Come Up with Research Ideas in Computer Vision?</a> - Jia-Bin Huang (UIUC)</li>
<li><a target="_blank" rel="nofollow" href="http://www.slideshare.net/jbhuang/how-to-read-academic-papers">How to Read Academic Papers</a> - Jia-Bin Huang (UIUC)</li>
</ul>
<h4><a href="#time-management" aria-hidden="true" class="anchor" id="user-content-time-management"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Time Management</h4>
<ul>
<li><a target="_blank" rel="nofollow" href="https://www.youtube.com/watch?v=oTugjssqOT0">Time Management</a> - Randy Pausch (CMU)</li>
</ul>
<h2><a href="#blogs" aria-hidden="true" class="anchor" id="user-content-blogs"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Blogs</h2>
<ul>
<li><a target="_blank" rel="nofollow" href="http://www.learnopencv.com/">Learn OpenCV</a> - Satya Mallick</li>
<li><a target="_blank" rel="nofollow" href="http://www.computervisionblog.com/">Tombone's Computer Vision Blog</a> - Tomasz Malisiewicz</li>
<li><a target="_blank" rel="nofollow" href="http://www.visiondummy.com/">Computer vision for dummies</a> - Vincent Spruyt</li>
<li><a target="_blank" rel="nofollow" href="http://karpathy.github.io/">Andrej Karpathy blog</a> - Andrej Karpathy</li>
<li><a target="_blank" rel="nofollow" href="http://aishack.in/">AI Shack</a> - Utkarsh Sinha</li>
<li><a target="_blank" rel="nofollow" href="http://computer-vision-talks.com/">Computer Vision Talks</a> - Eugene Khvedchenya</li>
<li><a id="user-content-jrobchin/Computer-Vision-Basics-with-Python-Keras-and-OpenCV" target="_blank" rel="noopener noreferrer" href="https://github.com/jrobchin/Computer-Vision-Basics-with-Python-Keras-and-OpenCV">Computer Vision Basics with Python Keras and OpenCV</a><span class="ml-1 text-grey-dark whitespace-no-wrap"><span class="text-orange-dark">151 <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 14 13" width="14" height="12" class="mr-1"><polygon points="14 5 9.1 4.36 7 0 4.9 4.36 0 5 3.6 8.26 2.67 13 7 10.67 11.33 13 10.4 8.26"></polygon></svg></span><span class="text-grey-dark">25 <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 14" width="10" height="12"><path d="M8,-8.47032947e-22 C7.09660216,-0.00238695453 6.3045861,0.603179379 6.07006224,1.47560813 C5.83553838,2.34803688 6.21717019,3.26909995 7,3.72 L7,5 L5,7 L3,5 L3,3.72 C3.78282981,3.26909995 4.16446162,2.34803688 3.92993776,1.47560813 C3.6954139,0.603179379 2.90339784,-0.00238695453 2,-4.44088363e-16 C1.09660216,-0.00238695453 0.304586097,0.603179379 0.0700622397,1.47560813 C-0.164461618,2.34803688 0.217170191,3.26909995 1,3.72 L1,5.5 L4,8.5 L4,10.28 C3.21717019,10.7309 2.83553838,11.6519631 3.07006224,12.5243919 C3.3045861,13.3968206 4.09660216,14.002387 5,14 C5.90339784,14.002387 6.6954139,13.3968206 6.92993776,12.5243919 C7.16446162,11.6519631 6.78282981,10.7309 6,10.28 L6,8.5 L9,5.5 L9,3.72 C9.78282981,3.26909995 10.1644616,2.34803688 9.92993776,1.47560813 C9.6954139,0.603179379 8.90339784,-0.00238695453 8,-8.47032947e-22 Z M2,3.2 C1.34,3.2 0.8,2.65 0.8,2 C0.8,1.35 1.35,0.8 2,0.8 C2.65,0.8 3.2,1.35 3.2,2 C3.2,2.65 2.65,3.2 2,3.2 Z M5,13.2 C4.34,13.2 3.8,12.65 3.8,12 C3.8,11.35 4.35,10.8 5,10.8 C5.65,10.8 6.2,11.35 6.2,12 C6.2,12.65 5.65,13.2 5,13.2 Z M8,3.2 C7.34,3.2 6.8,2.65 6.8,2 C6.8,1.35 7.35,0.8 8,0.8 C8.65,0.8 9.2,1.35 9.2,2 C9.2,2.65 8.65,3.2 8,3.2 Z"></path></svg></span></span> - Jason Chin (University of Western Ontario)</li>
</ul>
<h2><a href="#links" aria-hidden="true" class="anchor" id="user-content-links"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Links</h2>
<ul>
<li><a target="_blank" rel="nofollow" href="http://www.cs.ubc.ca/%7Elowe/vision.html">The Computer Vision Industry</a> - David Lowe</li>
<li><a target="_blank" rel="nofollow" href="http://hci.iwr.uni-heidelberg.de/Links/German_Vision/">German Computer Vision Research Groups &amp; Companies</a></li>
<li><a id="user-content-ChristosChristofidis/awesome-deep-learning" target="_blank" rel="noopener noreferrer" href="https://github.com/ChristosChristofidis/awesome-deep-learning">awesome-deep-learning</a><span class="ml-1 text-grey-dark whitespace-no-wrap"><span class="text-orange-dark">4k <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 14 13" width="14" height="12" class="mr-1"><polygon points="14 5 9.1 4.36 7 0 4.9 4.36 0 5 3.6 8.26 2.67 13 7 10.67 11.33 13 10.4 8.26"></polygon></svg></span><span class="text-green-dark">1k <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 14" width="10" height="12"><path d="M8,-8.47032947e-22 C7.09660216,-0.00238695453 6.3045861,0.603179379 6.07006224,1.47560813 C5.83553838,2.34803688 6.21717019,3.26909995 7,3.72 L7,5 L5,7 L3,5 L3,3.72 C3.78282981,3.26909995 4.16446162,2.34803688 3.92993776,1.47560813 C3.6954139,0.603179379 2.90339784,-0.00238695453 2,-4.44088363e-16 C1.09660216,-0.00238695453 0.304586097,0.603179379 0.0700622397,1.47560813 C-0.164461618,2.34803688 0.217170191,3.26909995 1,3.72 L1,5.5 L4,8.5 L4,10.28 C3.21717019,10.7309 2.83553838,11.6519631 3.07006224,12.5243919 C3.3045861,13.3968206 4.09660216,14.002387 5,14 C5.90339784,14.002387 6.6954139,13.3968206 6.92993776,12.5243919 C7.16446162,11.6519631 6.78282981,10.7309 6,10.28 L6,8.5 L9,5.5 L9,3.72 C9.78282981,3.26909995 10.1644616,2.34803688 9.92993776,1.47560813 C9.6954139,0.603179379 8.90339784,-0.00238695453 8,-8.47032947e-22 Z M2,3.2 C1.34,3.2 0.8,2.65 0.8,2 C0.8,1.35 1.35,0.8 2,0.8 C2.65,0.8 3.2,1.35 3.2,2 C3.2,2.65 2.65,3.2 2,3.2 Z M5,13.2 C4.34,13.2 3.8,12.65 3.8,12 C3.8,11.35 4.35,10.8 5,10.8 C5.65,10.8 6.2,11.35 6.2,12 C6.2,12.65 5.65,13.2 5,13.2 Z M8,3.2 C7.34,3.2 6.8,2.65 6.8,2 C6.8,1.35 7.35,0.8 8,0.8 C8.65,0.8 9.2,1.35 9.2,2 C9.2,2.65 8.65,3.2 8,3.2 Z"></path></svg></span></span></li>
<li><a id="user-content-josephmisiti/awesome-machine-learning" target="_blank" rel="noopener noreferrer" href="https://github.com/josephmisiti/awesome-machine-learning">awesome-machine-learning</a><span class="ml-1 text-grey-dark whitespace-no-wrap"><span class="text-orange-dark">4k <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 14 13" width="14" height="12" class="mr-1"><polygon points="14 5 9.1 4.36 7 0 4.9 4.36 0 5 3.6 8.26 2.67 13 7 10.67 11.33 13 10.4 8.26"></polygon></svg></span><span class="text-green-dark">678 <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 14" width="10" height="12"><path d="M8,-8.47032947e-22 C7.09660216,-0.00238695453 6.3045861,0.603179379 6.07006224,1.47560813 C5.83553838,2.34803688 6.21717019,3.26909995 7,3.72 L7,5 L5,7 L3,5 L3,3.72 C3.78282981,3.26909995 4.16446162,2.34803688 3.92993776,1.47560813 C3.6954139,0.603179379 2.90339784,-0.00238695453 2,-4.44088363e-16 C1.09660216,-0.00238695453 0.304586097,0.603179379 0.0700622397,1.47560813 C-0.164461618,2.34803688 0.217170191,3.26909995 1,3.72 L1,5.5 L4,8.5 L4,10.28 C3.21717019,10.7309 2.83553838,11.6519631 3.07006224,12.5243919 C3.3045861,13.3968206 4.09660216,14.002387 5,14 C5.90339784,14.002387 6.6954139,13.3968206 6.92993776,12.5243919 C7.16446162,11.6519631 6.78282981,10.7309 6,10.28 L6,8.5 L9,5.5 L9,3.72 C9.78282981,3.26909995 10.1644616,2.34803688 9.92993776,1.47560813 C9.6954139,0.603179379 8.90339784,-0.00238695453 8,-8.47032947e-22 Z M2,3.2 C1.34,3.2 0.8,2.65 0.8,2 C0.8,1.35 1.35,0.8 2,0.8 C2.65,0.8 3.2,1.35 3.2,2 C3.2,2.65 2.65,3.2 2,3.2 Z M5,13.2 C4.34,13.2 3.8,12.65 3.8,12 C3.8,11.35 4.35,10.8 5,10.8 C5.65,10.8 6.2,11.35 6.2,12 C6.2,12.65 5.65,13.2 5,13.2 Z M8,3.2 C7.34,3.2 6.8,2.65 6.8,2 C6.8,1.35 7.35,0.8 8,0.8 C8.65,0.8 9.2,1.35 9.2,2 C9.2,2.65 8.65,3.2 8,3.2 Z"></path></svg></span></span></li>
<li><a target="_blank" rel="nofollow" href="http://www.eecs.berkeley.edu/%7Ejunyanz/cat/cat_papers.html">Cat Paper Collection</a></li>
<li><a target="_blank" rel="nofollow" href="http://www.rsipvision.com/computer-vision-news/">Computer Vision News</a></li>
<li></li>
</ul>
<h2><a href="#songs" aria-hidden="true" class="anchor" id="user-content-songs"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Songs</h2>
<ul>
<li><a target="_blank" rel="nofollow" href="http://danielwedge.com/fmatrix/">The Fundamental Matrix Song</a></li>
<li><a target="_blank" rel="nofollow" href="http://danielwedge.com/ransac/">The RANSAC Song</a></li>
<li><a target="_blank" rel="nofollow" href="https://www.youtube.com/watch?v=DQWI1kvmwRg">Machine Learning A Cappella - Overfitting Thriller</a></li>
</ul>
<h2><a href="#licenses" aria-hidden="true" class="anchor" id="user-content-licenses"><svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Licenses</h2>
<p>License</p>
<p><a target="_blank" rel="nofollow" href="http://creativecommons.org/publicdomain/zero/1.0/"><img alt="CC0" target="_blank" rel="noopener noreferrer" src="https://camo.githubusercontent.com/c5160f944848828fa33126d9a697e9abe43ea98f/687474703a2f2f692e6372656174697665636f6d6d6f6e732e6f72672f702f7a65726f2f312e302f38387833312e706e67" data-canonical-src="http://i.creativecommons.org/p/zero/1.0/88x31.png" style="max-width:100%"></a></p>
<p>To the extent possible under law, <a target="_blank" rel="noopener noreferrer" href="https://github.com/jbhuang0604/awesome-computer-vision/blob/master/www.jiabinhuang.com">Jia-Bin Huang</a> has waived all copyright and related or neighboring rights to this work.</p>
</div></div></div><div class="w-full max-w-xs bg-grey-lightest fixed pin-r pin-t pin-b mt-15 lg:mt-0 lg:flex flex-col overflow-hidden z-20 hidden"><div class="flex-1 overflow-y-scroll scrolling-touch -mr-8 pr-8"><div class="m-4 text-grey leading-loose text-center text-sm"><noscript>Enable JavaScript for more features</noscript></div></div><div class="flex-none"><div class="ad border-t shadow-lg hidden lg:block p-4"></div></div></div><div style="position:fixed;bottom:30px;right:350px;cursor:pointer;transition:opacity .2s linear 0s,visibility;z-index:20;opacity:0;visibility:hidden"><div class="bg-grey-light p-2 rounded hidden lg:block"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 16" class="block" width="32" height="32"><path fill-rule="evenodd" d="M5 3L0 9h3v4h4V9h3z"></path></svg></div></div></div></div><script type="text/javascript" src="/static/js/main.510da053.js"></script></body></html>